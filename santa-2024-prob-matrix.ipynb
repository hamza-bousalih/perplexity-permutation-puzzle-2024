{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770b73fd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-15T11:53:35.074971Z",
     "iopub.status.busy": "2024-12-15T11:53:35.074574Z",
     "iopub.status.idle": "2024-12-15T11:53:39.744787Z",
     "shell.execute_reply": "2024-12-15T11:53:39.743735Z"
    },
    "papermill": {
     "duration": 4.679974,
     "end_time": "2024-12-15T11:53:39.747280",
     "exception": false,
     "start_time": "2024-12-15T11:53:35.067306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Evaluation metric for Santa 2024.\"\"\"\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from math import exp\n",
    "from collections import Counter\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "PAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str,\n",
    "    model_path: str = '/kaggle/input/gemma-2/transformers/gemma-2-9b/2',\n",
    "    load_in_8bit: bool = False,\n",
    "    clear_mem: bool = False,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the mean perplexity of submitted text permutations compared to an original text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    solution : DataFrame\n",
    "        DataFrame containing the original text in a column named 'text'.\n",
    "        Includes a row ID column specified by `row_id_column_name`.\n",
    "\n",
    "    submission : DataFrame\n",
    "        DataFrame containing the permuted text in a column named 'text'.\n",
    "        Must have the same row IDs as the solution.\n",
    "        Includes a row ID column specified by `row_id_column_name`.\n",
    "\n",
    "    row_id_column_name : str\n",
    "        Name of the column containing row IDs.\n",
    "        Ensures aligned comparison between solution and submission.\n",
    "\n",
    "    model_path : str, default='/kaggle/input/gemma-2/transformers/gemma-2-9b/2'\n",
    "        Path to the serialized LLM.\n",
    "\n",
    "    load_in_8bit : bool, default=False\n",
    "        Use 8-bit quantization for the model. Requires CUDA.\n",
    "\n",
    "    clear_mem : bool, default=False\n",
    "        Clear GPU memory after scoring by clearing the CUDA cache.\n",
    "        Useful for testing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean perplexity score. Lower is better.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ParticipantVisibleError\n",
    "        If the submission format is invalid or submitted strings are not valid permutations.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     'id': [0, 1],\n",
    "    ...     'text': [\"this is a normal english sentence\", \"the quick brown fox jumps over the lazy dog\"]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     'id': [0, 1],\n",
    "    ...     'text': [\"sentence english normal a is this\", \"lazy the over jumps fox brown quick the dog\"]\n",
    "    ... })\n",
    "    >>> score(solution, submission, 'id', model_path=model_path, clear_mem=True) > 0\n",
    "    True\n",
    "    \"\"\"\n",
    "    # Check that each submitted string is a permutation of the solution string\n",
    "    sol_counts = solution.loc[:, 'text'].str.split().apply(Counter)\n",
    "    sub_counts = submission.loc[:, 'text'].str.split().apply(Counter)\n",
    "    invalid_mask = sol_counts != sub_counts\n",
    "    if invalid_mask.any():\n",
    "        raise ParticipantVisibleError(\n",
    "            'At least one submitted string is not a valid permutation of the solution string.'\n",
    "        )\n",
    "\n",
    "    # Calculate perplexity for the submitted strings\n",
    "    sub_strings = [\n",
    "        ' '.join(s.split()) for s in submission['text'].tolist()\n",
    "    ]  # Split and rejoin to normalize whitespace\n",
    "    scorer = PerplexityCalculator(\n",
    "        model_path=model_path,\n",
    "        load_in_8bit=load_in_8bit,\n",
    "    )  # Initialize the perplexity calculator with a pre-trained model\n",
    "    perplexities = scorer.get_perplexity(\n",
    "        sub_strings\n",
    "    )  # Calculate perplexity for each submitted string\n",
    "\n",
    "    if clear_mem:\n",
    "        # Just move on if it fails. Not essential if we have the score.\n",
    "        try:\n",
    "            scorer.clear_gpu_memory()\n",
    "        except:\n",
    "            print('GPU memory clearing failed.')\n",
    "\n",
    "    return float(np.mean(perplexities))\n",
    "\n",
    "\n",
    "class PerplexityCalculator:\n",
    "    \"\"\"\n",
    "    Calculates perplexity of text using a pre-trained language model.\n",
    "\n",
    "    Adapted from https://github.com/asahi417/lmppl/blob/main/lmppl/ppl_recurrent_lm.py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Path to the pre-trained language model\n",
    "\n",
    "    load_in_8bit : bool, default=False\n",
    "        Use 8-bit quantization for the model. Requires CUDA.\n",
    "\n",
    "    device_map : str, default=\"auto\"\n",
    "        Device mapping for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        load_in_8bit: bool = False,\n",
    "        device_map: str = 'auto',\n",
    "    ):\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n",
    "        # Configure model loading based on quantization setting and device availability\n",
    "        if load_in_8bit:\n",
    "            if DEVICE.type != 'cuda':\n",
    "                raise ValueError('8-bit quantization requires CUDA device')\n",
    "            quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n",
    "            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                quantization_config=quantization_config,\n",
    "                device_map=device_map,\n",
    "            )\n",
    "        else:\n",
    "            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n",
    "                device_map=device_map,\n",
    "            )\n",
    "\n",
    "        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_perplexity(\n",
    "        self, input_texts: Union[str, List[str]], debug=False\n",
    "    ) -> Union[float, List[float]]:\n",
    "        \"\"\"\n",
    "        Calculates the perplexity of given texts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_texts : str or list of str\n",
    "            A single string or a list of strings.\n",
    "\n",
    "        batch_size : int, default=None\n",
    "            Batch size for processing. Defaults to the number of input texts.\n",
    "\n",
    "        debug : bool, default=False\n",
    "            Print debugging information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float or list of float\n",
    "            A single perplexity value if input is a single string,\n",
    "            or a list of perplexity values if input is a list of strings.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import pandas as pd\n",
    "        >>> model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n",
    "        >>> scorer = PerplexityCalculator(model_path=model_path)\n",
    "\n",
    "        >>> submission = pd.DataFrame({\n",
    "        ...     'id': [0, 1, 2],\n",
    "        ...     'text': [\"this is a normal english sentence\", \"thsi is a slihgtly misspelled zr4g sentense\", \"the quick brown fox jumps over the lazy dog\"]\n",
    "        ... })\n",
    "        >>> perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n",
    "        >>> perplexities[0] < perplexities[1]\n",
    "        True\n",
    "        >>> perplexities[2] < perplexities[0]\n",
    "        True\n",
    "\n",
    "        >>> perplexities = scorer.get_perplexity([\"this is a sentence\", \"another sentence\"])\n",
    "        >>> all(p > 0 for p in perplexities)\n",
    "        True\n",
    "\n",
    "        >>> scorer.clear_gpu_memory()\n",
    "        \"\"\"\n",
    "        single_input = isinstance(input_texts, str)\n",
    "        input_texts = [input_texts] if single_input else input_texts\n",
    "\n",
    "        loss_list = []\n",
    "        with torch.no_grad():\n",
    "            # Process each sequence independently\n",
    "            for text in input_texts:\n",
    "                # Explicitly add sequence boundary tokens to the text\n",
    "                text_with_special = f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\"\n",
    "\n",
    "                # Tokenize\n",
    "                model_inputs = self.tokenizer(\n",
    "                    text_with_special,\n",
    "                    return_tensors='pt',\n",
    "                    add_special_tokens=False,\n",
    "                )\n",
    "\n",
    "                if 'token_type_ids' in model_inputs:\n",
    "                    model_inputs.pop('token_type_ids')\n",
    "\n",
    "                model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n",
    "\n",
    "                # Get model output\n",
    "                output = self.model(**model_inputs, use_cache=False)\n",
    "                logits = output['logits']\n",
    "\n",
    "                # Shift logits and labels for calculating loss\n",
    "                shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n",
    "                shift_labels = model_inputs['input_ids'][..., 1:].contiguous()  # Drop first input\n",
    "\n",
    "                # Calculate token-wise loss\n",
    "                loss = self.loss_fct(\n",
    "                    shift_logits.view(-1, shift_logits.size(-1)),\n",
    "                    shift_labels.view(-1)\n",
    "                )\n",
    "\n",
    "                # Calculate average loss\n",
    "                sequence_loss = loss.sum() / len(loss)\n",
    "                loss_list.append(sequence_loss.cpu().item())\n",
    "\n",
    "                # Debug output\n",
    "                if debug:\n",
    "                    print(f\"\\nProcessing: '{text}'\")\n",
    "                    print(f\"With special tokens: '{text_with_special}'\")\n",
    "                    print(f\"Input tokens: {model_inputs['input_ids'][0].tolist()}\")\n",
    "                    print(f\"Target tokens: {shift_labels[0].tolist()}\")\n",
    "                    print(f\"Input decoded: {self.tokenizer.decode(model_inputs['input_ids'][0])}\")\n",
    "                    print(f\"Target decoded: {self.tokenizer.decode(shift_labels[0])}\")\n",
    "                    print(f\"Individual losses: {loss.tolist()}\")\n",
    "                    print(f\"Average loss: {sequence_loss.item():.4f}\")\n",
    "\n",
    "        ppl = [exp(i) for i in loss_list]\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\nFinal perplexities:\")\n",
    "            for text, perp in zip(input_texts, ppl):\n",
    "                print(f\"Text: '{text}'\")\n",
    "                print(f\"Perplexity: {perp:.2f}\")\n",
    "\n",
    "        return ppl[0] if single_input else ppl\n",
    "\n",
    "    def clear_gpu_memory(self) -> None:\n",
    "        \"\"\"Clears GPU memory by deleting references and emptying caches.\"\"\"\n",
    "        if not torch.cuda.is_available():\n",
    "            return\n",
    "\n",
    "        # Delete model and tokenizer if they exist\n",
    "        if hasattr(self, 'model'):\n",
    "            del self.model\n",
    "        if hasattr(self, 'tokenizer'):\n",
    "            del self.tokenizer\n",
    "\n",
    "        # Run garbage collection\n",
    "        gc.collect()\n",
    "\n",
    "        # Clear CUDA cache and reset memory stats\n",
    "        with DEVICE:\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "    \n",
    "    def get_word_transition_matrix(self, sentence: str, debug=False):\n",
    "        \"\"\"\n",
    "        Calculate the transition probability matrix for words in a sentence.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str\n",
    "            The input sentence for which the transition probabilities are calculated.\n",
    "    \n",
    "        debug : bool, default=False\n",
    "            Print debugging information.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A DataFrame containing the transition probabilities between words.\n",
    "        \"\"\"\n",
    "        # Add special tokens to the input sentence\n",
    "        text_with_special = f\"{self.tokenizer.bos_token}{sentence}{self.tokenizer.eos_token}\"\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Input sentence: {sentence}\")\n",
    "            print(f\"Sentence with special tokens: {text_with_special}\")\n",
    "    \n",
    "        # Tokenize the sentence\n",
    "        model_inputs = self.tokenizer(\n",
    "            text_with_special,\n",
    "            return_tensors='pt',\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    \n",
    "        if 'token_type_ids' in model_inputs:\n",
    "            model_inputs.pop('token_type_ids')\n",
    "    \n",
    "        model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Tokenized input IDs: {model_inputs['input_ids'][0].tolist()}\")\n",
    "            print(f\"Decoded tokens: {self.tokenizer.convert_ids_to_tokens(model_inputs['input_ids'][0].tolist())}\")\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Get model output\n",
    "            output = self.model(**model_inputs, use_cache=False)\n",
    "            logits = output['logits']  # Shape: (batch_size, seq_len, vocab_size)\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Logits shape: {logits.shape}\")\n",
    "    \n",
    "        # Convert logits to probabilities using softmax\n",
    "        probabilities = F.softmax(logits, dim=-1).squeeze(0)  # Shape: (seq_len, vocab_size)\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Softmax probabilities shape: {probabilities.shape}\")\n",
    "    \n",
    "        # Map token IDs to words\n",
    "        tokens = model_inputs['input_ids'][0].tolist()\n",
    "        words = self.tokenizer.convert_ids_to_tokens(tokens)\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Tokens: {tokens}\")\n",
    "            print(f\"Words: {words}\")\n",
    "    \n",
    "        # Build transition probability matrix\n",
    "        transition_matrix = []\n",
    "        for i, word in enumerate(words[:-1]):  # Skip the last token as it has no next word\n",
    "            next_probs = probabilities[i].cpu().numpy()  # Probabilities for the next token\n",
    "            transition_matrix.append((word, next_probs))\n",
    "    \n",
    "            if debug:\n",
    "                print(f\"Word: {word}\")\n",
    "                print(f\"Next token probabilities: {next_probs}\")\n",
    "    \n",
    "        # Convert to DataFrame for easier readability\n",
    "        vocab_words = self.tokenizer.convert_ids_to_tokens(range(len(next_probs)))\n",
    "        df = pd.DataFrame(\n",
    "            {word: probs for word, probs in transition_matrix},\n",
    "            index=vocab_words\n",
    "        ).T\n",
    "    \n",
    "        if debug:\n",
    "            print(f\"Transition matrix DataFrame:\\n{df}\")\n",
    "    \n",
    "        return df.loc[words[1:-1], words[1:-1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720894e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T11:53:39.758744Z",
     "iopub.status.busy": "2024-12-15T11:53:39.757639Z",
     "iopub.status.idle": "2024-12-15T11:59:58.915321Z",
     "shell.execute_reply": "2024-12-15T11:59:58.913534Z"
    },
    "papermill": {
     "duration": 379.167308,
     "end_time": "2024-12-15T11:59:58.919223",
     "exception": false,
     "start_time": "2024-12-15T11:53:39.751915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cb3c441aff494fbb61eb06e4cac84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: the quick brown fox jumps over the lazy dog\n",
      "Sentence with special tokens: <bos>the quick brown fox jumps over the lazy dog<eos>\n",
      "Tokenized input IDs: [2, 1175, 4320, 8426, 25341, 36271, 1163, 573, 27894, 5929, 1]\n",
      "Decoded tokens: ['<bos>', 'the', '▁quick', '▁brown', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog', '<eos>']\n",
      "Logits shape: torch.Size([1, 11, 256000])\n",
      "Softmax probabilities shape: torch.Size([11, 256000])\n",
      "Tokens: [2, 1175, 4320, 8426, 25341, 36271, 1163, 573, 27894, 5929, 1]\n",
      "Words: ['<bos>', 'the', '▁quick', '▁brown', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog', '<eos>']\n",
      "Word: <bos>\n",
      "Next token probabilities: [8.7685074e-11 2.8206819e-06 2.3340651e-06 ... 9.1015817e-10 5.7863359e-09\n",
      " 8.7873937e-11]\n",
      "Word: the\n",
      "Next token probabilities: [1.5185595e-21 1.2502646e-07 8.4630794e-17 ... 8.9107701e-18 4.6668081e-17\n",
      " 2.5440984e-21]\n",
      "Word: ▁quick\n",
      "Next token probabilities: [2.2997401e-22 5.6259658e-08 6.5498395e-14 ... 4.6967011e-17 8.7147481e-17\n",
      " 1.8868373e-20]\n",
      "Word: ▁brown\n",
      "Next token probabilities: [2.7472666e-18 9.2790918e-07 9.9733226e-09 ... 1.1464409e-12 2.3266775e-12\n",
      " 3.6065760e-17]\n",
      "Word: ▁fox\n",
      "Next token probabilities: [4.4717595e-18 9.8483752e-06 7.4394642e-09 ... 3.0699906e-13 6.1922197e-11\n",
      " 1.9656191e-16]\n",
      "Word: ▁jumps\n",
      "Next token probabilities: [4.6137482e-15 1.4511392e-06 2.9684020e-07 ... 3.8535808e-10 1.5226738e-09\n",
      " 3.6519618e-15]\n",
      "Word: ▁over\n",
      "Next token probabilities: [3.5992807e-13 3.4907282e-06 1.0404823e-07 ... 5.1826854e-10 1.4536226e-09\n",
      " 3.0562434e-13]\n",
      "Word: ▁the\n",
      "Next token probabilities: [1.5921845e-18 1.2817211e-06 1.3712782e-09 ... 6.7652237e-13 1.0482647e-11\n",
      " 5.3978121e-17]\n",
      "Word: ▁lazy\n",
      "Next token probabilities: [3.1119759e-17 1.2009571e-06 3.2710496e-08 ... 4.2580602e-11 6.2040019e-11\n",
      " 5.1280414e-17]\n",
      "Word: ▁dog\n",
      "Next token probabilities: [7.7320305e-19 5.8210123e-04 4.9169313e-09 ... 9.3961212e-15 1.4295166e-10\n",
      " 1.6468671e-18]\n",
      "Transition matrix DataFrame:\n",
      "               <pad>         <eos>         <bos>         <unk>        <mask>  \\\n",
      "<bos>   8.768507e-11  2.820682e-06  2.334065e-06  9.729913e-11  9.833538e-10   \n",
      "the     1.518560e-21  1.250265e-07  8.463079e-17  3.530991e-18  3.574210e-17   \n",
      "▁quick  2.299740e-22  5.625966e-08  6.549839e-14  8.971059e-19  6.743648e-16   \n",
      "▁brown  2.747267e-18  9.279092e-07  9.973323e-09  8.810970e-16  5.135275e-13   \n",
      "▁fox    4.471759e-18  9.848375e-06  7.439464e-09  1.364290e-15  5.811374e-11   \n",
      "▁jumps  4.613748e-15  1.451139e-06  2.968402e-07  2.681263e-14  6.713349e-11   \n",
      "▁over   3.599281e-13  3.490728e-06  1.040482e-07  8.185314e-13  3.933180e-10   \n",
      "▁the    1.592185e-18  1.281721e-06  1.371278e-09  7.404272e-16  1.856211e-12   \n",
      "▁lazy   3.111976e-17  1.200957e-06  3.271050e-08  5.999824e-15  3.416491e-11   \n",
      "▁dog    7.732030e-19  5.821012e-04  4.916931e-09  4.367617e-16  8.965697e-13   \n",
      "\n",
      "             <2mass>       [@BOS@]     <unused0>     <unused1>     <unused2>  \\\n",
      "<bos>   8.803667e-11  8.781731e-11  8.965530e-11  8.776539e-11  9.336165e-11   \n",
      "the     2.325175e-21  1.684262e-21  1.102790e-20  1.255812e-21  1.320553e-18   \n",
      "▁quick  1.874583e-21  4.002011e-22  1.517974e-20  2.724661e-22  6.146432e-19   \n",
      "▁brown  1.356851e-17  3.286267e-18  6.326745e-17  3.175357e-18  4.891133e-16   \n",
      "▁fox    6.380579e-17  4.991959e-18  7.068722e-17  5.304070e-18  2.402501e-15   \n",
      "▁jumps  4.891192e-15  5.173109e-15  1.124034e-14  4.704208e-15  1.953201e-14   \n",
      "▁over   3.575858e-13  3.829770e-13  5.106124e-13  3.629393e-13  6.556368e-13   \n",
      "▁the    1.822784e-17  1.849617e-18  1.443125e-16  1.835896e-18  4.620167e-16   \n",
      "▁lazy   7.264350e-17  4.005685e-17  5.957673e-16  3.217099e-17  2.752311e-15   \n",
      "▁dog    3.386236e-18  1.353219e-18  2.286275e-17  8.210760e-19  5.884405e-16   \n",
      "\n",
      "        ...  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>   ...                                    2.981904e-09   \n",
      "the     ...                                    4.025468e-16   \n",
      "▁quick  ...                                    9.627933e-16   \n",
      "▁brown  ...                                    1.052934e-13   \n",
      "▁fox    ...                                    7.250182e-13   \n",
      "▁jumps  ...                                    3.911236e-10   \n",
      "▁over   ...                                    9.829776e-10   \n",
      "▁the    ...                                    6.149456e-12   \n",
      "▁lazy   ...                                    1.723762e-11   \n",
      "▁dog    ...                                    1.249314e-12   \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                       2.359339e-09   \n",
      "the                                         2.794661e-18   \n",
      "▁quick                                      5.932774e-16   \n",
      "▁brown                                      4.278197e-13   \n",
      "▁fox                                        9.973447e-12   \n",
      "▁jumps                                      8.460178e-10   \n",
      "▁over                                       1.273034e-09   \n",
      "▁the                                        1.612323e-11   \n",
      "▁lazy                                       3.302691e-11   \n",
      "▁dog                                        9.855822e-12   \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        1.932901e-09    \n",
      "the                                          6.072353e-18    \n",
      "▁quick                                       2.795282e-15    \n",
      "▁brown                                       3.756161e-12    \n",
      "▁fox                                         1.332511e-11    \n",
      "▁jumps                                       5.343395e-10    \n",
      "▁over                                        1.144414e-09    \n",
      "▁the                                         9.873565e-12    \n",
      "▁lazy                                        8.057585e-11    \n",
      "▁dog                                         5.362627e-12    \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        2.028075e-09      \n",
      "the                                          4.905005e-19      \n",
      "▁quick                                       6.538876e-15      \n",
      "▁brown                                       3.270806e-12      \n",
      "▁fox                                         1.683319e-11      \n",
      "▁jumps                                       4.211394e-10      \n",
      "▁over                                        1.577922e-09      \n",
      "▁the                                         2.845834e-11      \n",
      "▁lazy                                        1.636022e-10      \n",
      "▁dog                                         7.140691e-13      \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        1.207352e-09        \n",
      "the                                          1.429575e-18        \n",
      "▁quick                                       1.257670e-16        \n",
      "▁brown                                       4.011927e-12        \n",
      "▁fox                                         2.827918e-12        \n",
      "▁jumps                                       2.618327e-10        \n",
      "▁over                                        1.952537e-09        \n",
      "▁the                                         7.265125e-11        \n",
      "▁lazy                                        9.007577e-11        \n",
      "▁dog                                         1.172661e-13        \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        1.413002e-09          \n",
      "the                                          2.817882e-17          \n",
      "▁quick                                       3.175455e-14          \n",
      "▁brown                                       1.234083e-12          \n",
      "▁fox                                         3.214613e-12          \n",
      "▁jumps                                       1.752990e-10          \n",
      "▁over                                        5.938217e-10          \n",
      "▁the                                         2.623685e-12          \n",
      "▁lazy                                        2.410997e-11          \n",
      "▁dog                                         3.094458e-13          \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        1.241720e-09            \n",
      "the                                          3.948116e-18            \n",
      "▁quick                                       2.650639e-17            \n",
      "▁brown                                       2.522628e-12            \n",
      "▁fox                                         2.476189e-12            \n",
      "▁jumps                                       3.425694e-10            \n",
      "▁over                                        5.492665e-10            \n",
      "▁the                                         4.568319e-12            \n",
      "▁lazy                                        6.882323e-11            \n",
      "▁dog                                         5.057560e-14            \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        9.101582e-10              \n",
      "the                                          8.910770e-18              \n",
      "▁quick                                       4.696701e-17              \n",
      "▁brown                                       1.146441e-12              \n",
      "▁fox                                         3.069991e-13              \n",
      "▁jumps                                       3.853581e-10              \n",
      "▁over                                        5.182685e-10              \n",
      "▁the                                         6.765224e-13              \n",
      "▁lazy                                        4.258060e-11              \n",
      "▁dog                                         9.396121e-15              \n",
      "\n",
      "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
      "<bos>                                        5.786336e-09                \n",
      "the                                          4.666808e-17                \n",
      "▁quick                                       8.714748e-17                \n",
      "▁brown                                       2.326677e-12                \n",
      "▁fox                                         6.192220e-11                \n",
      "▁jumps                                       1.522674e-09                \n",
      "▁over                                        1.453623e-09                \n",
      "▁the                                         1.048265e-11                \n",
      "▁lazy                                        6.204002e-11                \n",
      "▁dog                                         1.429517e-10                \n",
      "\n",
      "          <unused99>  \n",
      "<bos>   8.787394e-11  \n",
      "the     2.544098e-21  \n",
      "▁quick  1.886837e-20  \n",
      "▁brown  3.606576e-17  \n",
      "▁fox    1.965619e-16  \n",
      "▁jumps  3.651962e-15  \n",
      "▁over   3.056243e-13  \n",
      "▁the    5.397812e-17  \n",
      "▁lazy   5.128041e-17  \n",
      "▁dog    1.646867e-18  \n",
      "\n",
      "[10 rows x 256000 columns]\n",
      "                 the    ▁quick    ▁brown      ▁fox        ▁jumps     ▁over  \\\n",
      "the     1.783058e-07  0.000027  0.000003  0.000004  4.135287e-10  0.000005   \n",
      "▁quick  3.573963e-07  0.000112  0.253200  0.000200  5.550260e-06  0.000017   \n",
      "▁brown  1.002134e-08  0.000010  0.000014  0.940248  6.980826e-05  0.000016   \n",
      "▁fox    1.855237e-07  0.000029  0.000088  0.000693  6.046017e-01  0.001072   \n",
      "▁jumps  3.800448e-07  0.000030  0.000019  0.000009  1.235868e-05  0.969625   \n",
      "▁over   4.139934e-04  0.000023  0.000014  0.000004  2.068456e-06  0.000040   \n",
      "▁the    3.671033e-07  0.001038  0.000192  0.000027  4.187962e-06  0.000020   \n",
      "▁lazy   2.491684e-07  0.000006  0.000913  0.000361  4.308223e-06  0.000002   \n",
      "▁dog    1.944718e-04  0.000523  0.000056  0.000004  1.766617e-04  0.000025   \n",
      "\n",
      "            ▁the         ▁lazy      ▁dog  \n",
      "the     0.001885  7.967157e-07  0.000055  \n",
      "▁quick  0.000453  1.292991e-06  0.000003  \n",
      "▁brown  0.000137  3.494785e-05  0.015788  \n",
      "▁fox    0.000990  9.191806e-05  0.000037  \n",
      "▁jumps  0.001350  1.667308e-05  0.000024  \n",
      "▁over   0.926231  1.333397e-02  0.000111  \n",
      "▁the    0.000391  9.630541e-01  0.005644  \n",
      "▁lazy   0.000104  1.450001e-04  0.953291  \n",
      "▁dog    0.009295  4.737631e-05  0.001805  \n"
     ]
    }
   ],
   "source": [
    "scorer = PerplexityCalculator(model_path=\"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\")\n",
    "\n",
    "sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "transition_matrix = scorer.get_word_transition_matrix(sentence, True)\n",
    "\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967946ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T11:59:58.934001Z",
     "iopub.status.busy": "2024-12-15T11:59:58.932521Z",
     "iopub.status.idle": "2024-12-15T11:59:58.956502Z",
     "shell.execute_reply": "2024-12-15T11:59:58.955211Z"
    },
    "papermill": {
     "duration": 0.034073,
     "end_time": "2024-12-15T11:59:58.958846",
     "exception": false,
     "start_time": "2024-12-15T11:59:58.924773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>▁quick</th>\n",
       "      <th>▁brown</th>\n",
       "      <th>▁fox</th>\n",
       "      <th>▁jumps</th>\n",
       "      <th>▁over</th>\n",
       "      <th>▁the</th>\n",
       "      <th>▁lazy</th>\n",
       "      <th>▁dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.783058e-07</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.135287e-10</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>7.967157e-07</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁quick</th>\n",
       "      <td>3.573963e-07</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.550260e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1.292991e-06</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁brown</th>\n",
       "      <td>1.002134e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.940248</td>\n",
       "      <td>6.980826e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>3.494785e-05</td>\n",
       "      <td>0.015788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁fox</th>\n",
       "      <td>1.855237e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>6.046017e-01</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>9.191806e-05</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁jumps</th>\n",
       "      <td>3.800448e-07</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.235868e-05</td>\n",
       "      <td>0.969625</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>1.667308e-05</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁over</th>\n",
       "      <td>4.139934e-04</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.068456e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.926231</td>\n",
       "      <td>1.333397e-02</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁the</th>\n",
       "      <td>3.671033e-07</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>4.187962e-06</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>9.630541e-01</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁lazy</th>\n",
       "      <td>2.491684e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>4.308223e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.450001e-04</td>\n",
       "      <td>0.953291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁dog</th>\n",
       "      <td>1.944718e-04</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.766617e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.009295</td>\n",
       "      <td>4.737631e-05</td>\n",
       "      <td>0.001805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the    ▁quick    ▁brown      ▁fox        ▁jumps     ▁over  \\\n",
       "the     1.783058e-07  0.000027  0.000003  0.000004  4.135287e-10  0.000005   \n",
       "▁quick  3.573963e-07  0.000112  0.253200  0.000200  5.550260e-06  0.000017   \n",
       "▁brown  1.002134e-08  0.000010  0.000014  0.940248  6.980826e-05  0.000016   \n",
       "▁fox    1.855237e-07  0.000029  0.000088  0.000693  6.046017e-01  0.001072   \n",
       "▁jumps  3.800448e-07  0.000030  0.000019  0.000009  1.235868e-05  0.969625   \n",
       "▁over   4.139934e-04  0.000023  0.000014  0.000004  2.068456e-06  0.000040   \n",
       "▁the    3.671033e-07  0.001038  0.000192  0.000027  4.187962e-06  0.000020   \n",
       "▁lazy   2.491684e-07  0.000006  0.000913  0.000361  4.308223e-06  0.000002   \n",
       "▁dog    1.944718e-04  0.000523  0.000056  0.000004  1.766617e-04  0.000025   \n",
       "\n",
       "            ▁the         ▁lazy      ▁dog  \n",
       "the     0.001885  7.967157e-07  0.000055  \n",
       "▁quick  0.000453  1.292991e-06  0.000003  \n",
       "▁brown  0.000137  3.494785e-05  0.015788  \n",
       "▁fox    0.000990  9.191806e-05  0.000037  \n",
       "▁jumps  0.001350  1.667308e-05  0.000024  \n",
       "▁over   0.926231  1.333397e-02  0.000111  \n",
       "▁the    0.000391  9.630541e-01  0.005644  \n",
       "▁lazy   0.000104  1.450001e-04  0.953291  \n",
       "▁dog    0.009295  4.737631e-05  0.001805  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e047dd",
   "metadata": {
    "papermill": {
     "duration": 0.004868,
     "end_time": "2024-12-15T11:59:58.969175",
     "exception": false,
     "start_time": "2024-12-15T11:59:58.964307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c10d1f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T11:59:58.984504Z",
     "iopub.status.busy": "2024-12-15T11:59:58.984036Z",
     "iopub.status.idle": "2024-12-15T12:00:04.170387Z",
     "shell.execute_reply": "2024-12-15T12:00:04.169001Z"
    },
    "papermill": {
     "duration": 5.198618,
     "end_time": "2024-12-15T12:00:04.172967",
     "exception": false,
     "start_time": "2024-12-15T11:59:58.974349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4ee24264364d29aba35f9d8b14c2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-41): 42 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
       "          (rotary_emb): Gemma2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\n",
    "load_in_8bit = False\n",
    "device_map: str = 'auto'\n",
    "sentence = \"the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "if load_in_8bit:\n",
    "    if DEVICE.type != 'cuda':\n",
    "        raise ValueError('8-bit quantization requires CUDA device')\n",
    "    quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "else:\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n",
    "        device_map=device_map,\n",
    "    )\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012bbf25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:00:04.187290Z",
     "iopub.status.busy": "2024-12-15T12:00:04.186884Z",
     "iopub.status.idle": "2024-12-15T12:00:04.192720Z",
     "shell.execute_reply": "2024-12-15T12:00:04.191582Z"
    },
    "papermill": {
     "duration": 0.016112,
     "end_time": "2024-12-15T12:00:04.195430",
     "exception": false,
     "start_time": "2024-12-15T12:00:04.179318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: the quick brown fox jumps over the lazy dog\n",
      "Sentence with special tokens: <bos>the quick brown fox jumps over the lazy dog<eos>\n"
     ]
    }
   ],
   "source": [
    "text_with_special = f\"{tokenizer.bos_token}{sentence}{tokenizer.eos_token}\"\n",
    "    \n",
    "print(f\"Input sentence: {sentence}\")\n",
    "print(f\"Sentence with special tokens: {text_with_special}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbee0bcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:00:04.209354Z",
     "iopub.status.busy": "2024-12-15T12:00:04.208291Z",
     "iopub.status.idle": "2024-12-15T12:00:04.223764Z",
     "shell.execute_reply": "2024-12-15T12:00:04.222559Z"
    },
    "papermill": {
     "duration": 0.024955,
     "end_time": "2024-12-15T12:00:04.226178",
     "exception": false,
     "start_time": "2024-12-15T12:00:04.201223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  1175,  4320,  8426, 25341, 36271,  1163,   573, 27894,  5929,\n",
       "             1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Tokenize the sentence\n",
    "model_inputs = tokenizer(\n",
    "    text_with_special,\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=False,\n",
    ")\n",
    "\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1144d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:00:04.239608Z",
     "iopub.status.busy": "2024-12-15T12:00:04.239142Z",
     "iopub.status.idle": "2024-12-15T12:00:04.244430Z",
     "shell.execute_reply": "2024-12-15T12:00:04.243248Z"
    },
    "papermill": {
     "duration": 0.014785,
     "end_time": "2024-12-15T12:00:04.246799",
     "exception": false,
     "start_time": "2024-12-15T12:00:04.232014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'token_type_ids' in model_inputs:\n",
    "    model_inputs.pop('token_type_ids')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d163eaf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:00:04.260345Z",
     "iopub.status.busy": "2024-12-15T12:00:04.259928Z",
     "iopub.status.idle": "2024-12-15T12:00:04.266722Z",
     "shell.execute_reply": "2024-12-15T12:00:04.265537Z"
    },
    "papermill": {
     "duration": 0.016163,
     "end_time": "2024-12-15T12:00:04.268993",
     "exception": false,
     "start_time": "2024-12-15T12:00:04.252830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input IDs: [2, 1175, 4320, 8426, 25341, 36271, 1163, 573, 27894, 5929, 1]\n",
      "Decoded tokens: ['<bos>', 'the', '▁quick', '▁brown', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n",
    "\n",
    "print(f\"Tokenized input IDs: {model_inputs['input_ids'][0].tolist()}\")\n",
    "print(f\"Decoded tokens: {tokenizer.convert_ids_to_tokens(model_inputs['input_ids'][0].tolist())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826a5649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:00:04.282861Z",
     "iopub.status.busy": "2024-12-15T12:00:04.282419Z",
     "iopub.status.idle": "2024-12-15T12:05:52.451637Z",
     "shell.execute_reply": "2024-12-15T12:05:52.450421Z"
    },
    "papermill": {
     "duration": 348.187798,
     "end_time": "2024-12-15T12:05:52.462785",
     "exception": false,
     "start_time": "2024-12-15T12:00:04.274987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([1, 11, 256000])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Get model output\n",
    "    output = model(**model_inputs, use_cache=False)\n",
    "    logits = output['logits']  # Shape: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b412517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.478082Z",
     "iopub.status.busy": "2024-12-15T12:05:52.476956Z",
     "iopub.status.idle": "2024-12-15T12:05:52.489298Z",
     "shell.execute_reply": "2024-12-15T12:05:52.488053Z"
    },
    "papermill": {
     "duration": 0.022731,
     "end_time": "2024-12-15T12:05:52.492031",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.469300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax probabilities shape: torch.Size([11, 256000])\n"
     ]
    }
   ],
   "source": [
    "# Convert logits to probabilities using softmax\n",
    "probabilities = F.softmax(logits, dim=-1).squeeze(0)  # Shape: (seq_len, vocab_size)\n",
    "\n",
    "print(f\"Softmax probabilities shape: {probabilities.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f999aff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.506115Z",
     "iopub.status.busy": "2024-12-15T12:05:52.505723Z",
     "iopub.status.idle": "2024-12-15T12:05:52.569335Z",
     "shell.execute_reply": "2024-12-15T12:05:52.568097Z"
    },
    "papermill": {
     "duration": 0.07373,
     "end_time": "2024-12-15T12:05:52.571865",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.498135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8207e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa6b70d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.587482Z",
     "iopub.status.busy": "2024-12-15T12:05:52.586255Z",
     "iopub.status.idle": "2024-12-15T12:05:52.596545Z",
     "shell.execute_reply": "2024-12-15T12:05:52.595290Z"
    },
    "papermill": {
     "duration": 0.020484,
     "end_time": "2024-12-15T12:05:52.598733",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.578249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [2, 1175, 4320, 8426, 25341, 36271, 1163, 573, 27894, 5929, 1]\n",
      "Words: ['<bos>', 'the', '▁quick', '▁brown', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# Map token IDs to words\n",
    "tokens = model_inputs['input_ids'][0].tolist()\n",
    "words = tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Words: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13cddcf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.613613Z",
     "iopub.status.busy": "2024-12-15T12:05:52.612869Z",
     "iopub.status.idle": "2024-12-15T12:05:52.622665Z",
     "shell.execute_reply": "2024-12-15T12:05:52.621537Z"
    },
    "papermill": {
     "duration": 0.019964,
     "end_time": "2024-12-15T12:05:52.625043",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.605079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ▁dog\n",
      "Next token probabilities: [7.7320305e-19 5.8210123e-04 4.9169313e-09 ... 9.3961212e-15 1.4295166e-10\n",
      " 1.6468671e-18]\n"
     ]
    }
   ],
   "source": [
    "# Build transition probability matrix\n",
    "transition_matrix = []\n",
    "for i, word in enumerate(words[:-1]):  # Skip the last token as it has no next word\n",
    "    next_probs = probabilities[i].cpu().numpy()  # Probabilities for the next token\n",
    "    transition_matrix.append((word, next_probs))\n",
    "\n",
    "print(f\"Word: {word}\")\n",
    "print(f\"Next token probabilities: {next_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b71309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.640004Z",
     "iopub.status.busy": "2024-12-15T12:05:52.639621Z",
     "iopub.status.idle": "2024-12-15T12:05:52.647246Z",
     "shell.execute_reply": "2024-12-15T12:05:52.646258Z"
    },
    "papermill": {
     "duration": 0.017678,
     "end_time": "2024-12-15T12:05:52.649466",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.631788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.7685074e-11, 2.8206819e-06, 2.3340651e-06, ..., 9.1015817e-10,\n",
       "       5.7863359e-09, 8.7873937e-11], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c66308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.664497Z",
     "iopub.status.busy": "2024-12-15T12:05:52.664045Z",
     "iopub.status.idle": "2024-12-15T12:05:52.958437Z",
     "shell.execute_reply": "2024-12-15T12:05:52.957552Z"
    },
    "papermill": {
     "duration": 0.304894,
     "end_time": "2024-12-15T12:05:52.961153",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.656259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier readability\n",
    "vocab_words = tokenizer.convert_ids_to_tokens(range(len(next_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bcf95",
   "metadata": {
    "papermill": {
     "duration": 0.006122,
     "end_time": "2024-12-15T12:05:52.973976",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.967854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78472f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:52.988807Z",
     "iopub.status.busy": "2024-12-15T12:05:52.988350Z",
     "iopub.status.idle": "2024-12-15T12:05:53.161686Z",
     "shell.execute_reply": "2024-12-15T12:05:53.160485Z"
    },
    "papermill": {
     "duration": 0.183535,
     "end_time": "2024-12-15T12:05:53.164034",
     "exception": false,
     "start_time": "2024-12-15T12:05:52.980499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;pad&gt;</th>\n",
       "      <th>&lt;eos&gt;</th>\n",
       "      <th>&lt;bos&gt;</th>\n",
       "      <th>&lt;unk&gt;</th>\n",
       "      <th>&lt;mask&gt;</th>\n",
       "      <th>&lt;2mass&gt;</th>\n",
       "      <th>[@BOS@]</th>\n",
       "      <th>&lt;unused0&gt;</th>\n",
       "      <th>&lt;unused1&gt;</th>\n",
       "      <th>&lt;unused2&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</th>\n",
       "      <th>&lt;unused99&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;bos&gt;</th>\n",
       "      <td>8.768507e-11</td>\n",
       "      <td>2.820682e-06</td>\n",
       "      <td>2.334065e-06</td>\n",
       "      <td>9.729913e-11</td>\n",
       "      <td>9.833538e-10</td>\n",
       "      <td>8.803667e-11</td>\n",
       "      <td>8.781731e-11</td>\n",
       "      <td>8.965530e-11</td>\n",
       "      <td>8.776539e-11</td>\n",
       "      <td>9.336165e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.981904e-09</td>\n",
       "      <td>2.359339e-09</td>\n",
       "      <td>1.932901e-09</td>\n",
       "      <td>2.028075e-09</td>\n",
       "      <td>1.207352e-09</td>\n",
       "      <td>1.413002e-09</td>\n",
       "      <td>1.241720e-09</td>\n",
       "      <td>9.101582e-10</td>\n",
       "      <td>5.786336e-09</td>\n",
       "      <td>8.787394e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.518560e-21</td>\n",
       "      <td>1.250265e-07</td>\n",
       "      <td>8.463079e-17</td>\n",
       "      <td>3.530991e-18</td>\n",
       "      <td>3.574210e-17</td>\n",
       "      <td>2.325175e-21</td>\n",
       "      <td>1.684262e-21</td>\n",
       "      <td>1.102790e-20</td>\n",
       "      <td>1.255812e-21</td>\n",
       "      <td>1.320553e-18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.025468e-16</td>\n",
       "      <td>2.794661e-18</td>\n",
       "      <td>6.072353e-18</td>\n",
       "      <td>4.905005e-19</td>\n",
       "      <td>1.429575e-18</td>\n",
       "      <td>2.817882e-17</td>\n",
       "      <td>3.948116e-18</td>\n",
       "      <td>8.910770e-18</td>\n",
       "      <td>4.666808e-17</td>\n",
       "      <td>2.544098e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁quick</th>\n",
       "      <td>2.299740e-22</td>\n",
       "      <td>5.625966e-08</td>\n",
       "      <td>6.549839e-14</td>\n",
       "      <td>8.971059e-19</td>\n",
       "      <td>6.743648e-16</td>\n",
       "      <td>1.874583e-21</td>\n",
       "      <td>4.002011e-22</td>\n",
       "      <td>1.517974e-20</td>\n",
       "      <td>2.724661e-22</td>\n",
       "      <td>6.146432e-19</td>\n",
       "      <td>...</td>\n",
       "      <td>9.627933e-16</td>\n",
       "      <td>5.932774e-16</td>\n",
       "      <td>2.795282e-15</td>\n",
       "      <td>6.538876e-15</td>\n",
       "      <td>1.257670e-16</td>\n",
       "      <td>3.175455e-14</td>\n",
       "      <td>2.650639e-17</td>\n",
       "      <td>4.696701e-17</td>\n",
       "      <td>8.714748e-17</td>\n",
       "      <td>1.886837e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁brown</th>\n",
       "      <td>2.747267e-18</td>\n",
       "      <td>9.279092e-07</td>\n",
       "      <td>9.973323e-09</td>\n",
       "      <td>8.810970e-16</td>\n",
       "      <td>5.135275e-13</td>\n",
       "      <td>1.356851e-17</td>\n",
       "      <td>3.286267e-18</td>\n",
       "      <td>6.326745e-17</td>\n",
       "      <td>3.175357e-18</td>\n",
       "      <td>4.891133e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.052934e-13</td>\n",
       "      <td>4.278197e-13</td>\n",
       "      <td>3.756161e-12</td>\n",
       "      <td>3.270806e-12</td>\n",
       "      <td>4.011927e-12</td>\n",
       "      <td>1.234083e-12</td>\n",
       "      <td>2.522628e-12</td>\n",
       "      <td>1.146441e-12</td>\n",
       "      <td>2.326677e-12</td>\n",
       "      <td>3.606576e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁fox</th>\n",
       "      <td>4.471759e-18</td>\n",
       "      <td>9.848375e-06</td>\n",
       "      <td>7.439464e-09</td>\n",
       "      <td>1.364290e-15</td>\n",
       "      <td>5.811374e-11</td>\n",
       "      <td>6.380579e-17</td>\n",
       "      <td>4.991959e-18</td>\n",
       "      <td>7.068722e-17</td>\n",
       "      <td>5.304070e-18</td>\n",
       "      <td>2.402501e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.250182e-13</td>\n",
       "      <td>9.973447e-12</td>\n",
       "      <td>1.332511e-11</td>\n",
       "      <td>1.683319e-11</td>\n",
       "      <td>2.827918e-12</td>\n",
       "      <td>3.214613e-12</td>\n",
       "      <td>2.476189e-12</td>\n",
       "      <td>3.069991e-13</td>\n",
       "      <td>6.192220e-11</td>\n",
       "      <td>1.965619e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁jumps</th>\n",
       "      <td>4.613748e-15</td>\n",
       "      <td>1.451139e-06</td>\n",
       "      <td>2.968402e-07</td>\n",
       "      <td>2.681263e-14</td>\n",
       "      <td>6.713349e-11</td>\n",
       "      <td>4.891192e-15</td>\n",
       "      <td>5.173109e-15</td>\n",
       "      <td>1.124034e-14</td>\n",
       "      <td>4.704208e-15</td>\n",
       "      <td>1.953201e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.911236e-10</td>\n",
       "      <td>8.460178e-10</td>\n",
       "      <td>5.343395e-10</td>\n",
       "      <td>4.211394e-10</td>\n",
       "      <td>2.618327e-10</td>\n",
       "      <td>1.752990e-10</td>\n",
       "      <td>3.425694e-10</td>\n",
       "      <td>3.853581e-10</td>\n",
       "      <td>1.522674e-09</td>\n",
       "      <td>3.651962e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁over</th>\n",
       "      <td>3.599281e-13</td>\n",
       "      <td>3.490728e-06</td>\n",
       "      <td>1.040482e-07</td>\n",
       "      <td>8.185314e-13</td>\n",
       "      <td>3.933180e-10</td>\n",
       "      <td>3.575858e-13</td>\n",
       "      <td>3.829770e-13</td>\n",
       "      <td>5.106124e-13</td>\n",
       "      <td>3.629393e-13</td>\n",
       "      <td>6.556368e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>9.829776e-10</td>\n",
       "      <td>1.273034e-09</td>\n",
       "      <td>1.144414e-09</td>\n",
       "      <td>1.577922e-09</td>\n",
       "      <td>1.952537e-09</td>\n",
       "      <td>5.938217e-10</td>\n",
       "      <td>5.492665e-10</td>\n",
       "      <td>5.182685e-10</td>\n",
       "      <td>1.453623e-09</td>\n",
       "      <td>3.056243e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁the</th>\n",
       "      <td>1.592185e-18</td>\n",
       "      <td>1.281721e-06</td>\n",
       "      <td>1.371278e-09</td>\n",
       "      <td>7.404272e-16</td>\n",
       "      <td>1.856211e-12</td>\n",
       "      <td>1.822784e-17</td>\n",
       "      <td>1.849617e-18</td>\n",
       "      <td>1.443125e-16</td>\n",
       "      <td>1.835896e-18</td>\n",
       "      <td>4.620167e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>6.149456e-12</td>\n",
       "      <td>1.612323e-11</td>\n",
       "      <td>9.873565e-12</td>\n",
       "      <td>2.845834e-11</td>\n",
       "      <td>7.265125e-11</td>\n",
       "      <td>2.623685e-12</td>\n",
       "      <td>4.568319e-12</td>\n",
       "      <td>6.765224e-13</td>\n",
       "      <td>1.048265e-11</td>\n",
       "      <td>5.397812e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁lazy</th>\n",
       "      <td>3.111976e-17</td>\n",
       "      <td>1.200957e-06</td>\n",
       "      <td>3.271050e-08</td>\n",
       "      <td>5.999824e-15</td>\n",
       "      <td>3.416491e-11</td>\n",
       "      <td>7.264350e-17</td>\n",
       "      <td>4.005685e-17</td>\n",
       "      <td>5.957673e-16</td>\n",
       "      <td>3.217099e-17</td>\n",
       "      <td>2.752311e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.723762e-11</td>\n",
       "      <td>3.302691e-11</td>\n",
       "      <td>8.057585e-11</td>\n",
       "      <td>1.636022e-10</td>\n",
       "      <td>9.007577e-11</td>\n",
       "      <td>2.410997e-11</td>\n",
       "      <td>6.882323e-11</td>\n",
       "      <td>4.258060e-11</td>\n",
       "      <td>6.204002e-11</td>\n",
       "      <td>5.128041e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁dog</th>\n",
       "      <td>7.732030e-19</td>\n",
       "      <td>5.821012e-04</td>\n",
       "      <td>4.916931e-09</td>\n",
       "      <td>4.367617e-16</td>\n",
       "      <td>8.965697e-13</td>\n",
       "      <td>3.386236e-18</td>\n",
       "      <td>1.353219e-18</td>\n",
       "      <td>2.286275e-17</td>\n",
       "      <td>8.210760e-19</td>\n",
       "      <td>5.884405e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249314e-12</td>\n",
       "      <td>9.855822e-12</td>\n",
       "      <td>5.362627e-12</td>\n",
       "      <td>7.140691e-13</td>\n",
       "      <td>1.172661e-13</td>\n",
       "      <td>3.094458e-13</td>\n",
       "      <td>5.057560e-14</td>\n",
       "      <td>9.396121e-15</td>\n",
       "      <td>1.429517e-10</td>\n",
       "      <td>1.646867e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 256000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               <pad>         <eos>         <bos>         <unk>        <mask>  \\\n",
       "<bos>   8.768507e-11  2.820682e-06  2.334065e-06  9.729913e-11  9.833538e-10   \n",
       "the     1.518560e-21  1.250265e-07  8.463079e-17  3.530991e-18  3.574210e-17   \n",
       "▁quick  2.299740e-22  5.625966e-08  6.549839e-14  8.971059e-19  6.743648e-16   \n",
       "▁brown  2.747267e-18  9.279092e-07  9.973323e-09  8.810970e-16  5.135275e-13   \n",
       "▁fox    4.471759e-18  9.848375e-06  7.439464e-09  1.364290e-15  5.811374e-11   \n",
       "▁jumps  4.613748e-15  1.451139e-06  2.968402e-07  2.681263e-14  6.713349e-11   \n",
       "▁over   3.599281e-13  3.490728e-06  1.040482e-07  8.185314e-13  3.933180e-10   \n",
       "▁the    1.592185e-18  1.281721e-06  1.371278e-09  7.404272e-16  1.856211e-12   \n",
       "▁lazy   3.111976e-17  1.200957e-06  3.271050e-08  5.999824e-15  3.416491e-11   \n",
       "▁dog    7.732030e-19  5.821012e-04  4.916931e-09  4.367617e-16  8.965697e-13   \n",
       "\n",
       "             <2mass>       [@BOS@]     <unused0>     <unused1>     <unused2>  \\\n",
       "<bos>   8.803667e-11  8.781731e-11  8.965530e-11  8.776539e-11  9.336165e-11   \n",
       "the     2.325175e-21  1.684262e-21  1.102790e-20  1.255812e-21  1.320553e-18   \n",
       "▁quick  1.874583e-21  4.002011e-22  1.517974e-20  2.724661e-22  6.146432e-19   \n",
       "▁brown  1.356851e-17  3.286267e-18  6.326745e-17  3.175357e-18  4.891133e-16   \n",
       "▁fox    6.380579e-17  4.991959e-18  7.068722e-17  5.304070e-18  2.402501e-15   \n",
       "▁jumps  4.891192e-15  5.173109e-15  1.124034e-14  4.704208e-15  1.953201e-14   \n",
       "▁over   3.575858e-13  3.829770e-13  5.106124e-13  3.629393e-13  6.556368e-13   \n",
       "▁the    1.822784e-17  1.849617e-18  1.443125e-16  1.835896e-18  4.620167e-16   \n",
       "▁lazy   7.264350e-17  4.005685e-17  5.957673e-16  3.217099e-17  2.752311e-15   \n",
       "▁dog    3.386236e-18  1.353219e-18  2.286275e-17  8.210760e-19  5.884405e-16   \n",
       "\n",
       "        ...  \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>   ...                                    2.981904e-09   \n",
       "the     ...                                    4.025468e-16   \n",
       "▁quick  ...                                    9.627933e-16   \n",
       "▁brown  ...                                    1.052934e-13   \n",
       "▁fox    ...                                    7.250182e-13   \n",
       "▁jumps  ...                                    3.911236e-10   \n",
       "▁over   ...                                    9.829776e-10   \n",
       "▁the    ...                                    6.149456e-12   \n",
       "▁lazy   ...                                    1.723762e-11   \n",
       "▁dog    ...                                    1.249314e-12   \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                       2.359339e-09   \n",
       "the                                         2.794661e-18   \n",
       "▁quick                                      5.932774e-16   \n",
       "▁brown                                      4.278197e-13   \n",
       "▁fox                                        9.973447e-12   \n",
       "▁jumps                                      8.460178e-10   \n",
       "▁over                                       1.273034e-09   \n",
       "▁the                                        1.612323e-11   \n",
       "▁lazy                                       3.302691e-11   \n",
       "▁dog                                        9.855822e-12   \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        1.932901e-09    \n",
       "the                                          6.072353e-18    \n",
       "▁quick                                       2.795282e-15    \n",
       "▁brown                                       3.756161e-12    \n",
       "▁fox                                         1.332511e-11    \n",
       "▁jumps                                       5.343395e-10    \n",
       "▁over                                        1.144414e-09    \n",
       "▁the                                         9.873565e-12    \n",
       "▁lazy                                        8.057585e-11    \n",
       "▁dog                                         5.362627e-12    \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        2.028075e-09      \n",
       "the                                          4.905005e-19      \n",
       "▁quick                                       6.538876e-15      \n",
       "▁brown                                       3.270806e-12      \n",
       "▁fox                                         1.683319e-11      \n",
       "▁jumps                                       4.211394e-10      \n",
       "▁over                                        1.577922e-09      \n",
       "▁the                                         2.845834e-11      \n",
       "▁lazy                                        1.636022e-10      \n",
       "▁dog                                         7.140691e-13      \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        1.207352e-09        \n",
       "the                                          1.429575e-18        \n",
       "▁quick                                       1.257670e-16        \n",
       "▁brown                                       4.011927e-12        \n",
       "▁fox                                         2.827918e-12        \n",
       "▁jumps                                       2.618327e-10        \n",
       "▁over                                        1.952537e-09        \n",
       "▁the                                         7.265125e-11        \n",
       "▁lazy                                        9.007577e-11        \n",
       "▁dog                                         1.172661e-13        \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        1.413002e-09          \n",
       "the                                          2.817882e-17          \n",
       "▁quick                                       3.175455e-14          \n",
       "▁brown                                       1.234083e-12          \n",
       "▁fox                                         3.214613e-12          \n",
       "▁jumps                                       1.752990e-10          \n",
       "▁over                                        5.938217e-10          \n",
       "▁the                                         2.623685e-12          \n",
       "▁lazy                                        2.410997e-11          \n",
       "▁dog                                         3.094458e-13          \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        1.241720e-09            \n",
       "the                                          3.948116e-18            \n",
       "▁quick                                       2.650639e-17            \n",
       "▁brown                                       2.522628e-12            \n",
       "▁fox                                         2.476189e-12            \n",
       "▁jumps                                       3.425694e-10            \n",
       "▁over                                        5.492665e-10            \n",
       "▁the                                         4.568319e-12            \n",
       "▁lazy                                        6.882323e-11            \n",
       "▁dog                                         5.057560e-14            \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        9.101582e-10              \n",
       "the                                          8.910770e-18              \n",
       "▁quick                                       4.696701e-17              \n",
       "▁brown                                       1.146441e-12              \n",
       "▁fox                                         3.069991e-13              \n",
       "▁jumps                                       3.853581e-10              \n",
       "▁over                                        5.182685e-10              \n",
       "▁the                                         6.765224e-13              \n",
       "▁lazy                                        4.258060e-11              \n",
       "▁dog                                         9.396121e-15              \n",
       "\n",
       "        \\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t  \\\n",
       "<bos>                                        5.786336e-09                \n",
       "the                                          4.666808e-17                \n",
       "▁quick                                       8.714748e-17                \n",
       "▁brown                                       2.326677e-12                \n",
       "▁fox                                         6.192220e-11                \n",
       "▁jumps                                       1.522674e-09                \n",
       "▁over                                        1.453623e-09                \n",
       "▁the                                         1.048265e-11                \n",
       "▁lazy                                        6.204002e-11                \n",
       "▁dog                                         1.429517e-10                \n",
       "\n",
       "          <unused99>  \n",
       "<bos>   8.787394e-11  \n",
       "the     2.544098e-21  \n",
       "▁quick  1.886837e-20  \n",
       "▁brown  3.606576e-17  \n",
       "▁fox    1.965619e-16  \n",
       "▁jumps  3.651962e-15  \n",
       "▁over   3.056243e-13  \n",
       "▁the    5.397812e-17  \n",
       "▁lazy   5.128041e-17  \n",
       "▁dog    1.646867e-18  \n",
       "\n",
       "[10 rows x 256000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {word: probs for word, probs in transition_matrix},\n",
    "    index=vocab_words\n",
    ").T\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fce3a35b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:53.181096Z",
     "iopub.status.busy": "2024-12-15T12:05:53.180251Z",
     "iopub.status.idle": "2024-12-15T12:05:53.187212Z",
     "shell.execute_reply": "2024-12-15T12:05:53.186132Z"
    },
    "papermill": {
     "duration": 0.017424,
     "end_time": "2024-12-15T12:05:53.189182",
     "exception": false,
     "start_time": "2024-12-15T12:05:53.171758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', '▁quick', '▁brown', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "102e1723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:05:53.205662Z",
     "iopub.status.busy": "2024-12-15T12:05:53.205239Z",
     "iopub.status.idle": "2024-12-15T12:05:53.245286Z",
     "shell.execute_reply": "2024-12-15T12:05:53.244189Z"
    },
    "papermill": {
     "duration": 0.051121,
     "end_time": "2024-12-15T12:05:53.247725",
     "exception": false,
     "start_time": "2024-12-15T12:05:53.196604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>▁quick</th>\n",
       "      <th>▁brown</th>\n",
       "      <th>▁fox</th>\n",
       "      <th>▁jumps</th>\n",
       "      <th>▁over</th>\n",
       "      <th>▁the</th>\n",
       "      <th>▁lazy</th>\n",
       "      <th>▁dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.783058e-07</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.135287e-10</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>7.967157e-07</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁quick</th>\n",
       "      <td>3.573963e-07</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.253200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.550260e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1.292991e-06</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁brown</th>\n",
       "      <td>1.002134e-08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.940248</td>\n",
       "      <td>6.980826e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>3.494785e-05</td>\n",
       "      <td>0.015788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁fox</th>\n",
       "      <td>1.855237e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>6.046017e-01</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>9.191806e-05</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁jumps</th>\n",
       "      <td>3.800448e-07</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.235868e-05</td>\n",
       "      <td>0.969625</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>1.667308e-05</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁over</th>\n",
       "      <td>4.139934e-04</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.068456e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.926231</td>\n",
       "      <td>1.333397e-02</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁the</th>\n",
       "      <td>3.671033e-07</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>4.187962e-06</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>9.630541e-01</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁lazy</th>\n",
       "      <td>2.491684e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>4.308223e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>1.450001e-04</td>\n",
       "      <td>0.953291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>▁dog</th>\n",
       "      <td>1.944718e-04</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.766617e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.009295</td>\n",
       "      <td>4.737631e-05</td>\n",
       "      <td>0.001805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 the    ▁quick    ▁brown      ▁fox        ▁jumps     ▁over  \\\n",
       "the     1.783058e-07  0.000027  0.000003  0.000004  4.135287e-10  0.000005   \n",
       "▁quick  3.573963e-07  0.000112  0.253200  0.000200  5.550260e-06  0.000017   \n",
       "▁brown  1.002134e-08  0.000010  0.000014  0.940248  6.980826e-05  0.000016   \n",
       "▁fox    1.855237e-07  0.000029  0.000088  0.000693  6.046017e-01  0.001072   \n",
       "▁jumps  3.800448e-07  0.000030  0.000019  0.000009  1.235868e-05  0.969625   \n",
       "▁over   4.139934e-04  0.000023  0.000014  0.000004  2.068456e-06  0.000040   \n",
       "▁the    3.671033e-07  0.001038  0.000192  0.000027  4.187962e-06  0.000020   \n",
       "▁lazy   2.491684e-07  0.000006  0.000913  0.000361  4.308223e-06  0.000002   \n",
       "▁dog    1.944718e-04  0.000523  0.000056  0.000004  1.766617e-04  0.000025   \n",
       "\n",
       "            ▁the         ▁lazy      ▁dog  \n",
       "the     0.001885  7.967157e-07  0.000055  \n",
       "▁quick  0.000453  1.292991e-06  0.000003  \n",
       "▁brown  0.000137  3.494785e-05  0.015788  \n",
       "▁fox    0.000990  9.191806e-05  0.000037  \n",
       "▁jumps  0.001350  1.667308e-05  0.000024  \n",
       "▁over   0.926231  1.333397e-02  0.000111  \n",
       "▁the    0.000391  9.630541e-01  0.005644  \n",
       "▁lazy   0.000104  1.450001e-04  0.953291  \n",
       "▁dog    0.009295  4.737631e-05  0.001805  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[words[1:-1], words[1:-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5b8db6",
   "metadata": {
    "papermill": {
     "duration": 0.007304,
     "end_time": "2024-12-15T12:05:53.262881",
     "exception": false,
     "start_time": "2024-12-15T12:05:53.255577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10229277,
     "sourceId": 88046,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 76277,
     "modelInstanceId": 72255,
     "sourceId": 104492,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 743.82532,
   "end_time": "2024-12-15T12:05:56.152996",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-15T11:53:32.327676",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1b1a520da6404e3e9f1655b3472cb342": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2522549efbfa4ea6bdd64d1a1be45022": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff49a7ee88ba491595682db4f434bc66",
       "max": 8.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_66c2b23b8da0452c94f778198cb7b5cd",
       "tabbable": null,
       "tooltip": null,
       "value": 8.0
      }
     },
     "2a3dc2eed088495395b60ae6db7fc74b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ccae4567569443e884e595c7fba85e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b1a520da6404e3e9f1655b3472cb342",
       "placeholder": "​",
       "style": "IPY_MODEL_fb3c33798c204315b32613312d1555dc",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "2e8f313d3d5449e79d9b0197f0510fd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b33095891fa0473490f63a16b126e462",
       "placeholder": "​",
       "style": "IPY_MODEL_84a7d73468f243fba7333675b2c42ad5",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "428e1787a0b342118d79dec9560004a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49cb3c441aff494fbb61eb06e4cac84c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ccae4567569443e884e595c7fba85e9",
        "IPY_MODEL_b35ae9cea50949988ae162b10788a994",
        "IPY_MODEL_90727e5d867e4747b8843012a5b79753"
       ],
       "layout": "IPY_MODEL_5b76df2d281e41b4a4de93d17eabf4ba",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5b76df2d281e41b4a4de93d17eabf4ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "607534250e644711bec22073341a874c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66c2b23b8da0452c94f778198cb7b5cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "84a7d73468f243fba7333675b2c42ad5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8d003a98228a4f7d825a0563fefa65da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90727e5d867e4747b8843012a5b79753": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a3dc2eed088495395b60ae6db7fc74b",
       "placeholder": "​",
       "style": "IPY_MODEL_8d003a98228a4f7d825a0563fefa65da",
       "tabbable": null,
       "tooltip": null,
       "value": " 8/8 [00:03&lt;00:00,  1.87it/s]"
      }
     },
     "b33095891fa0473490f63a16b126e462": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b35ae9cea50949988ae162b10788a994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_607534250e644711bec22073341a874c",
       "max": 8.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef3f3c7a925449aa8d903978655139b0",
       "tabbable": null,
       "tooltip": null,
       "value": 8.0
      }
     },
     "babaf136ccad43a7a82b08692418d505": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0d424e7e3f34c2687e40b2bd40571aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e761beaaedbd4b6bb3c7718c9a033aba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_babaf136ccad43a7a82b08692418d505",
       "placeholder": "​",
       "style": "IPY_MODEL_e0d424e7e3f34c2687e40b2bd40571aa",
       "tabbable": null,
       "tooltip": null,
       "value": " 8/8 [00:03&lt;00:00,  2.46it/s]"
      }
     },
     "ed4ee24264364d29aba35f9d8b14c2fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2e8f313d3d5449e79d9b0197f0510fd8",
        "IPY_MODEL_2522549efbfa4ea6bdd64d1a1be45022",
        "IPY_MODEL_e761beaaedbd4b6bb3c7718c9a033aba"
       ],
       "layout": "IPY_MODEL_428e1787a0b342118d79dec9560004a1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ef3f3c7a925449aa8d903978655139b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fb3c33798c204315b32613312d1555dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ff49a7ee88ba491595682db4f434bc66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
