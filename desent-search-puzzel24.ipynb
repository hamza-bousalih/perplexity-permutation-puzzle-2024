{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":88046,"databundleVersionId":10229277,"sourceType":"competition"},{"sourceId":104492,"sourceType":"modelInstanceVersion","modelInstanceId":72255,"modelId":76277}],"dockerImageVersionId":30805,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nfrom math import exp\nfrom collections import Counter\nfrom typing import List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\n\nos.environ['OMP_NUM_THREADS'] = '1'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nPAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(\n    solution: pd.DataFrame,\n    submission: pd.DataFrame,\n    row_id_column_name: str,\n    model_path: str = '/kaggle/input/gemma-2/transformers/gemma-2-9b/2',\n    load_in_8bit: bool = False,\n    clear_mem: bool = False,\n) -> float:\n    # Check that each submitted string is a permutation of the solution string\n    sol_counts = solution.loc[:, 'text'].str.split().apply(Counter)\n    sub_counts = submission.loc[:, 'text'].str.split().apply(Counter)\n    invalid_mask = sol_counts != sub_counts\n    if invalid_mask.any():\n        raise ParticipantVisibleError(\n            'At least one submitted string is not a valid permutation of the solution string.'\n        )\n\n    # Calculate perplexity for the submitted strings\n    sub_strings = [\n        ' '.join(s.split()) for s in submission['text'].tolist()\n    ]  # Split and rejoin to normalize whitespace\n    scorer = PerplexityCalculator(\n        model_path=model_path,\n        load_in_8bit=load_in_8bit,\n    )  # Initialize the perplexity calculator with a pre-trained model\n    perplexities = scorer.get_perplexity(\n        sub_strings\n    )  # Calculate perplexity for each submitted string\n\n    if clear_mem:\n        # Just move on if it fails. Not essential if we have the score.\n        try:\n            scorer.clear_gpu_memory()\n        except:\n            print('GPU memory clearing failed.')\n\n    return float(np.mean(perplexities))\n\n\nclass PerplexityCalculator:\n    def __init__(\n        self,\n        model_path: str,\n        load_in_8bit: bool = False,\n        device_map: str = 'auto',\n    ):\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n        # Configure model loading based on quantization setting and device availability\n        if load_in_8bit:\n            if DEVICE.type != 'cuda':\n                raise ValueError('8-bit quantization requires CUDA device')\n            quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                quantization_config=quantization_config,\n                device_map=device_map,\n            )\n        else:\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n                device_map=device_map,\n            )\n\n        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n\n        self.model.eval()\n\n    def get_perplexity(\n        self, input_texts: Union[str, List[str]], debug=False\n    ) -> Union[float, List[float]]:\n        single_input = isinstance(input_texts, str)\n        input_texts = [input_texts] if single_input else input_texts\n\n        loss_list = []\n        with torch.no_grad():\n            # Process each sequence independently\n            for text in input_texts:\n                # Explicitly add sequence boundary tokens to the text\n                text_with_special = f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\"\n\n                # Tokenize\n                model_inputs = self.tokenizer(\n                    text_with_special,\n                    return_tensors='pt',\n                    add_special_tokens=False,\n                )\n\n                if 'token_type_ids' in model_inputs:\n                    model_inputs.pop('token_type_ids')\n\n                model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n\n                # Get model output\n                output = self.model(**model_inputs, use_cache=False)\n                logits = output['logits']\n\n                # Shift logits and labels for calculating loss\n                shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n                shift_labels = model_inputs['input_ids'][..., 1:].contiguous()  # Drop first input\n\n                # Calculate token-wise loss\n                loss = self.loss_fct(\n                    shift_logits.view(-1, shift_logits.size(-1)),\n                    shift_labels.view(-1)\n                )\n\n                # Calculate average loss\n                sequence_loss = loss.sum() / len(loss)\n                loss_list.append(sequence_loss.cpu().item())\n\n                # Debug output\n                if debug:\n                    print(f\"\\nProcessing: '{text}'\")\n                    print(f\"With special tokens: '{text_with_special}'\")\n                    print(f\"Input tokens: {model_inputs['input_ids'][0].tolist()}\")\n                    print(f\"Target tokens: {shift_labels[0].tolist()}\")\n                    print(f\"Input decoded: {self.tokenizer.decode(model_inputs['input_ids'][0])}\")\n                    print(f\"Target decoded: {self.tokenizer.decode(shift_labels[0])}\")\n                    print(f\"Individual losses: {loss.tolist()}\")\n                    print(f\"Average loss: {sequence_loss.item():.4f}\")\n\n        ppl = [exp(i) for i in loss_list]\n\n        if debug:\n            print(\"\\nFinal perplexities:\")\n            for text, perp in zip(input_texts, ppl):\n                print(f\"Text: '{text}'\")\n                print(f\"Perplexity: {perp:.2f}\")\n\n        return ppl[0] if single_input else ppl\n\n    def clear_gpu_memory(self) -> None:\n        if not torch.cuda.is_available():\n            return\n\n        # Delete model and tokenizer if they exist\n        if hasattr(self, 'model'):\n            del self.model\n        if hasattr(self, 'tokenizer'):\n            del self.tokenizer\n\n        # Run garbage collection\n        gc.collect()\n\n        # Clear CUDA cache and reset memory stats\n        with DEVICE:\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            torch.cuda.reset_peak_memory_stats()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:22:29.434947Z","iopub.execute_input":"2024-12-16T23:22:29.435201Z","iopub.status.idle":"2024-12-16T23:22:33.977726Z","shell.execute_reply.started":"2024-12-16T23:22:29.435174Z","shell.execute_reply":"2024-12-16T23:22:33.976779Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nmodel_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\nscorer = PerplexityCalculator(model_path=model_path)\n\n# submission = pd.DataFrame({\n#      'id': [0, 1, 2],\n#      'text': [\"this is a normal english sentence\", \"thsi is a slihgtly misspelled zr4g sentense\", \"the quick brown fox jumps over the lazy dog\"]\n# })\n# perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n# perplexities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:22:33.979596Z","iopub.execute_input":"2024-12-16T23:22:33.980408Z","iopub.status.idle":"2024-12-16T23:25:23.318729Z","shell.execute_reply.started":"2024-12-16T23:22:33.980367Z","shell.execute_reply":"2024-12-16T23:25:23.318030Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30cf65cb1dd04b5e8fa75e40cbaa43f7"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"sentences = pd.read_csv(\"/kaggle/input/santa-2024/sample_submission.csv\")\nsentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:25:23.319706Z","iopub.execute_input":"2024-12-16T23:25:23.320191Z","iopub.status.idle":"2024-12-16T23:25:23.345185Z","shell.execute_reply.started":"2024-12-16T23:25:23.320164Z","shell.execute_reply":"2024-12-16T23:25:23.344499Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0  advent chimney elf family fireplace gingerbrea...\n1   1  advent chimney elf family fireplace gingerbrea...\n2   2  yuletide decorations gifts cheer holiday carol...\n3   3  yuletide decorations gifts cheer holiday carol...\n4   4  hohoho candle poinsettia snowglobe peppermint ...\n5   5  advent chimney elf family fireplace gingerbrea...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>hohoho candle poinsettia snowglobe peppermint ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"sentence = sentences['text'][0]\nsentence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:38:51.955497Z","iopub.execute_input":"2024-12-16T23:38:51.955866Z","iopub.status.idle":"2024-12-16T23:38:51.961605Z","shell.execute_reply.started":"2024-12-16T23:38:51.955837Z","shell.execute_reply":"2024-12-16T23:38:51.960677Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"import random\n\ndef calculate_cost(sentence):\n    submission = pd.DataFrame({\n         'id': [0],\n         'text': [\" \".join(sentence)]\n    })\n    perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n    return perplexities[0]\n\ndef generate_initial_solution(words):\n    shuffled_words = words[:]\n    random.shuffle(shuffled_words)\n    return shuffled_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:49:08.234815Z","iopub.execute_input":"2024-12-16T23:49:08.235770Z","iopub.status.idle":"2024-12-16T23:49:08.240564Z","shell.execute_reply.started":"2024-12-16T23:49:08.235706Z","shell.execute_reply":"2024-12-16T23:49:08.239773Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def local_search(words, max_iter):\n    n = len(words)\n    \n    current_solution = generate_initial_solution(words)\n    current_cost = calculate_cost(current_solution)\n    \n    iterations = 0\n\n    while iterations < max_iter:\n        iterations += 1\n        print(f\"------------------ [{iterations}] ------------------\")\n        \n        for i in range(n):\n            for j in range(i + 1, n):\n                new_solution = current_solution[:]\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                \n                new_cost = calculate_cost(new_solution) \n                \n                if new_cost < current_cost:\n                    print(f\"sentence: {' '.join(new_solution)} -> perplexity: {new_cost}\")\n                    current_solution = new_solution\n                    current_cost = new_cost\n                    break\n\n    return current_solution, current_cost\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T23:53:40.913141Z","iopub.execute_input":"2024-12-16T23:53:40.913853Z","iopub.status.idle":"2024-12-16T23:53:40.919411Z","shell.execute_reply.started":"2024-12-16T23:53:40.913816Z","shell.execute_reply":"2024-12-16T23:53:40.918544Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"words, score = local_search(sentences['text'][0].split(\" \"), max_iter=20)\n\" \".join(words)\n# sentence: reindeer mistletoe elf scrooge gingerbread family ornament advent chimney fireplace -> perplexity: 532.3726691377844\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T00:01:39.956425Z","iopub.execute_input":"2024-12-17T00:01:39.956819Z","iopub.status.idle":"2024-12-17T00:03:10.716010Z","shell.execute_reply.started":"2024-12-17T00:01:39.956763Z","shell.execute_reply":"2024-12-17T00:03:10.715102Z"}},"outputs":[{"name":"stdout","text":"------------------ [1] ------------------\nsentence: gingerbread ornament scrooge chimney family fireplace reindeer advent mistletoe elf -> perplexity: 1894.8121816143816\nsentence: gingerbread ornament fireplace chimney family scrooge reindeer advent mistletoe elf -> perplexity: 1601.8368003527937\nsentence: gingerbread ornament fireplace elf family scrooge reindeer advent mistletoe chimney -> perplexity: 1540.4713962049877\nsentence: gingerbread ornament fireplace elf scrooge family reindeer advent mistletoe chimney -> perplexity: 1487.2551219966645\nsentence: gingerbread ornament fireplace elf scrooge family reindeer mistletoe advent chimney -> perplexity: 1397.1468893399162\n------------------ [2] ------------------\nsentence: gingerbread family fireplace elf scrooge ornament reindeer mistletoe advent chimney -> perplexity: 1386.2742059875643\nsentence: gingerbread family advent elf scrooge ornament reindeer mistletoe fireplace chimney -> perplexity: 1237.8035409730126\nsentence: gingerbread family advent elf scrooge mistletoe reindeer ornament fireplace chimney -> perplexity: 1167.3599206126853\nsentence: gingerbread family advent elf scrooge mistletoe reindeer chimney fireplace ornament -> perplexity: 1105.234158889827\n------------------ [3] ------------------\nsentence: reindeer family advent elf scrooge mistletoe gingerbread chimney fireplace ornament -> perplexity: 1088.0990914837041\nsentence: reindeer elf advent family scrooge mistletoe gingerbread chimney fireplace ornament -> perplexity: 867.5082310343188\nsentence: reindeer elf family advent scrooge mistletoe gingerbread chimney fireplace ornament -> perplexity: 796.0703011721198\nsentence: reindeer elf family gingerbread scrooge mistletoe advent chimney fireplace ornament -> perplexity: 792.9667171920373\n------------------ [4] ------------------\nsentence: reindeer mistletoe family gingerbread scrooge elf advent chimney fireplace ornament -> perplexity: 702.5295750239817\nsentence: reindeer mistletoe gingerbread family scrooge elf advent chimney fireplace ornament -> perplexity: 589.282826961637\n------------------ [5] ------------------\n------------------ [6] ------------------\n------------------ [7] ------------------\n------------------ [8] ------------------\n------------------ [9] ------------------\n------------------ [10] ------------------\n------------------ [11] ------------------\n------------------ [12] ------------------\n------------------ [13] ------------------\n------------------ [14] ------------------\n------------------ [15] ------------------\n------------------ [16] ------------------\n------------------ [17] ------------------\n------------------ [18] ------------------\n------------------ [19] ------------------\n------------------ [20] ------------------\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'reindeer mistletoe gingerbread family scrooge elf advent chimney fireplace ornament'"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}