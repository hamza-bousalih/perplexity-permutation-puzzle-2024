{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":88046,"databundleVersionId":10229277,"sourceType":"competition"},{"sourceId":104492,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":72255,"modelId":76277}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport os\nfrom math import exp\nfrom collections import Counter\nfrom typing import List, Optional, Union\n\nimport numpy as np\nimport pandas as pd\nimport transformers\nimport torch\n\nfrom collections import deque\nfrom typing import Tuple, List\nfrom collections import deque\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-12-21T13:35:53.816363Z","iopub.execute_input":"2024-12-21T13:35:53.816688Z","iopub.status.idle":"2024-12-21T13:35:57.626786Z","shell.execute_reply.started":"2024-12-21T13:35:53.816662Z","shell.execute_reply":"2024-12-21T13:35:57.625931Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"os.environ['OMP_NUM_THREADS'] = '1'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\nPAD_TOKEN_LABEL_ID = torch.nn.CrossEntropyLoss().ignore_index\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass ParticipantVisibleError(Exception):\n    pass\n\ndef score(\n    solution: pd.DataFrame,\n    submission: pd.DataFrame,\n    row_id_column_name: str,\n    model_path: str = '/kaggle/input/gemma-2/transformers/gemma-2-9b/2',\n    load_in_8bit: bool = False,\n    clear_mem: bool = False,\n) -> float:\n    # Check that each submitted string is a permutation of the solution string\n    sol_counts = solution.loc[:, 'text'].str.split().apply(Counter)\n    sub_counts = submission.loc[:, 'text'].str.split().apply(Counter)\n    invalid_mask = sol_counts != sub_counts\n    if invalid_mask.any():\n        raise ParticipantVisibleError(\n            'At least one submitted string is not a valid permutation of the solution string.'\n        )\n\n    # Calculate perplexity for the submitted strings\n    sub_strings = [\n        ' '.join(s.split()) for s in submission['text'].tolist()\n    ]  # Split and rejoin to normalize whitespace\n    scorer = PerplexityCalculator(\n        model_path=model_path,\n        load_in_8bit=load_in_8bit,\n    )  # Initialize the perplexity calculator with a pre-trained model\n    perplexities = scorer.get_perplexity(\n        sub_strings\n    )  # Calculate perplexity for each submitted string\n\n    if clear_mem:\n        # Just move on if it fails. Not essential if we have the score.\n        try:\n            scorer.clear_gpu_memory()\n        except:\n            print('GPU memory clearing failed.')\n\n    return float(np.mean(perplexities))\n\nclass PerplexityCalculator:\n    def __init__(\n        self,\n        model_path: str,\n        load_in_8bit: bool = False,\n        device_map: str = 'auto',\n    ):\n        self.tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n        # Configure model loading based on quantization setting and device availability\n        if load_in_8bit:\n            if DEVICE.type != 'cuda':\n                raise ValueError('8-bit quantization requires CUDA device')\n            quantization_config = transformers.BitsAndBytesConfig(load_in_8bit=True)\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                quantization_config=quantization_config,\n                device_map=device_map,\n            )\n        else:\n            self.model = transformers.AutoModelForCausalLM.from_pretrained(\n                model_path,\n                torch_dtype=torch.float16 if DEVICE.type == 'cuda' else torch.float32,\n                device_map=device_map,\n            )\n\n        self.loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n\n        self.model.eval()\n\n    def get_perplexity(\n        self, input_texts: Union[str, List[str]], debug=False\n    ) -> Union[float, List[float]]:\n        single_input = isinstance(input_texts, str)\n        input_texts = [input_texts] if single_input else input_texts\n\n        loss_list = []\n        with torch.no_grad():\n            # Process each sequence independently\n            for text in input_texts:\n                # Explicitly add sequence boundary tokens to the text\n                text_with_special = f\"{self.tokenizer.bos_token}{text}{self.tokenizer.eos_token}\"\n\n                # Tokenize\n                model_inputs = self.tokenizer(\n                    text_with_special,\n                    return_tensors='pt',\n                    add_special_tokens=False,\n                )\n\n                if 'token_type_ids' in model_inputs:\n                    model_inputs.pop('token_type_ids')\n\n                model_inputs = {k: v.to(DEVICE) for k, v in model_inputs.items()}\n\n                # Get model output\n                output = self.model(**model_inputs, use_cache=False)\n                logits = output['logits']\n\n                # Shift logits and labels for calculating loss\n                shift_logits = logits[..., :-1, :].contiguous()  # Drop last prediction\n                shift_labels = model_inputs['input_ids'][..., 1:].contiguous()  # Drop first input\n\n                # Calculate token-wise loss\n                loss = self.loss_fct(\n                    shift_logits.view(-1, shift_logits.size(-1)),\n                    shift_labels.view(-1)\n                )\n\n                # Calculate average loss\n                sequence_loss = loss.sum() / len(loss)\n                loss_list.append(sequence_loss.cpu().item())\n\n                # Debug output\n                if debug:\n                    print(f\"\\nProcessing: '{text}'\")\n                    print(f\"With special tokens: '{text_with_special}'\")\n                    print(f\"Input tokens: {model_inputs['input_ids'][0].tolist()}\")\n                    print(f\"Target tokens: {shift_labels[0].tolist()}\")\n                    print(f\"Input decoded: {self.tokenizer.decode(model_inputs['input_ids'][0])}\")\n                    print(f\"Target decoded: {self.tokenizer.decode(shift_labels[0])}\")\n                    print(f\"Individual losses: {loss.tolist()}\")\n                    print(f\"Average loss: {sequence_loss.item():.4f}\")\n\n        ppl = [exp(i) for i in loss_list]\n\n        if debug:\n            print(\"\\nFinal perplexities:\")\n            for text, perp in zip(input_texts, ppl):\n                print(f\"Text: '{text}'\")\n                print(f\"Perplexity: {perp:.2f}\")\n\n        return ppl[0] if single_input else ppl\n\n    def clear_gpu_memory(self) -> None:\n        if not torch.cuda.is_available():\n            return\n\n        # Delete model and tokenizer if they exist\n        if hasattr(self, 'model'):\n            del self.model\n        if hasattr(self, 'tokenizer'):\n            del self.tokenizer\n\n        # Run garbage collection\n        gc.collect()\n\n        # Clear CUDA cache and reset memory stats\n        with DEVICE:\n            torch.cuda.empty_cache()\n            torch.cuda.ipc_collect()\n            torch.cuda.reset_peak_memory_stats()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-12-21T13:35:57.628083Z","iopub.execute_input":"2024-12-21T13:35:57.628556Z","iopub.status.idle":"2024-12-21T13:35:57.717025Z","shell.execute_reply.started":"2024-12-21T13:35:57.628523Z","shell.execute_reply":"2024-12-21T13:35:57.715642Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model_path = \"/kaggle/input/gemma-2/transformers/gemma-2-9b/2\"\nscorer = PerplexityCalculator(model_path=model_path)","metadata":{"execution":{"iopub.status.busy":"2024-12-21T13:35:57.718994Z","iopub.execute_input":"2024-12-21T13:35:57.719304Z","iopub.status.idle":"2024-12-21T13:38:29.576606Z","shell.execute_reply.started":"2024-12-21T13:35:57.719274Z","shell.execute_reply":"2024-12-21T13:38:29.575837Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb1f9801c4cd41d691e8ab0eb205be90"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/santa-2024/sample_submission.csv\")\nsubmission","metadata":{"execution":{"iopub.status.busy":"2024-12-21T13:38:29.577756Z","iopub.execute_input":"2024-12-21T13:38:29.578178Z","iopub.status.idle":"2024-12-21T13:38:29.606958Z","shell.execute_reply.started":"2024-12-21T13:38:29.578155Z","shell.execute_reply":"2024-12-21T13:38:29.606217Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0  advent chimney elf family fireplace gingerbrea...\n1   1  advent chimney elf family fireplace gingerbrea...\n2   2  yuletide decorations gifts cheer holiday carol...\n3   3  yuletide decorations gifts cheer holiday carol...\n4   4  hohoho candle poinsettia snowglobe peppermint ...\n5   5  advent chimney elf family fireplace gingerbrea...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>yuletide decorations gifts cheer holiday carol...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>hohoho candle poinsettia snowglobe peppermint ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>advent chimney elf family fireplace gingerbrea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n# perplexities","metadata":{"execution":{"iopub.status.busy":"2024-12-21T13:38:29.607655Z","iopub.execute_input":"2024-12-21T13:38:29.607859Z","iopub.status.idle":"2024-12-21T13:38:29.611163Z","shell.execute_reply.started":"2024-12-21T13:38:29.607842Z","shell.execute_reply":"2024-12-21T13:38:29.610209Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"---\n# TabuSearch","metadata":{}},{"cell_type":"code","source":"class TabuSearch:\n    def __init__(self, words: list, calculate_perplexity, tabu_tenure=5, stop_on_non_improvement=20, max_iter=100, debug=False):\n        self.words = words\n        self.tabu_tenure = tabu_tenure\n        self.stop_on_non_improvement = stop_on_non_improvement\n        self.max_iter = max_iter\n        self.calculate_perplexity = calculate_perplexity\n        self.tabu_list = deque(maxlen=self.tabu_tenure)\n        self.debug = debug\n\n    def log(self, msg):\n        if self.debug:\n            print(f\"[LOCAL SEARCH] {msg}\")\n    \n    def is_sentence_visited(self, sentence: np.ndarray):\n        return tuple(sentence) in self.tabu_list\n    \n    def to_sentence_text(self, sentence):\n        return \" \".join([self.words[i] for i in sentence])\n    \n    def to_tabulist(self, sentence):\n        self.tabu_list.append(tuple(sentence))\n\n    def get_candidates(self, sentence: np.ndarray) -> list:\n        neighbors = []\n        \n        for _ in range(len(sentence)):\n            node1 = 0\n            node2 = 0\n            \n            while node1 == node2:\n                node1 = random.randint(1, len(sentence) - 1)\n                node2 = random.randint(1, len(sentence) - 1)\n                \n            if node1 > node2:\n                node1, node2 = node2, node1  # Swap to ensure node1 < node2\n\n            # Use NumPy slicing and concatenation\n            tmp = sentence[node1:node2]\n            tmp_route = np.concatenate((sentence[:node1], tmp[::-1], sentence[node2:]))\n            neighbors.append(tmp_route)\n        \n        return neighbors\n\n    def optimize(self, current_sentence: np.ndarray) -> Tuple[np.ndarray, float]:\n        self.log(f\"start {current_sentence}\")\n        current_perplexity = self.calculate_perplexity(current_sentence)\n        \n        best_sentence = current_sentence\n        best_perplexity = current_perplexity\n        \n        no_improvement = 0\n        itr = 1\n        \n        while no_improvement < self.stop_on_non_improvement and itr <= self.max_iter:\n            # self.log(f\"[ITER] [{itr}] --- {best_perplexity}\")\n            \n            candidates = self.get_candidates(current_sentence)\n            \n            best_candidate = None\n            best_candidate_perplexity = None\n            \n            for candidate in candidates:\n                candidate_perplexity = self.calculate_perplexity(candidate)\n                if self.is_sentence_visited(candidate) or best_candidate_perplexity is None or candidate_perplexity < best_candidate_perplexity:\n                        best_candidate = candidate\n                        best_candidate_perplexity = candidate_perplexity\n            \n            # self.log(f\"[{best_candidate_perplexity}] {best_candidate}\")\n            \n            if best_candidate_perplexity < best_perplexity:\n                best_sentence = best_candidate\n                best_perplexity = best_candidate_perplexity\n                no_improvement = 0\n                self.log(f\"[IM] [{itr}/{self.max_iter}] [{best_perplexity}]\")\n            else:\n                no_improvement += 1\n                # self.log(f\"[NO IM] __{no_improvement}__\")\n            \n            current_sentence = best_candidate\n            current_perplexity = best_candidate_perplexity\n            \n            self.to_tabulist(best_sentence)\n            itr+=1\n\n            if(no_improvement == self.stop_on_non_improvement):\n                self.log(f\"[NO IM] break; {best_sentence} | {best_perplexity}\")\n            \n        return best_sentence, best_perplexity","metadata":{"execution":{"iopub.status.busy":"2024-12-21T14:05:17.286874Z","iopub.execute_input":"2024-12-21T14:05:17.287232Z","iopub.status.idle":"2024-12-21T14:05:17.297302Z","shell.execute_reply.started":"2024-12-21T14:05:17.287207Z","shell.execute_reply":"2024-12-21T14:05:17.296317Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# import numpy as np\n\n# words = submission['text'][0].split()\n# print(words)\n\n# init = np.random.permutation(len(words)).tolist()\n# print(init)\n\n# def __calculate_fitness(solution) -> float:\n#     sentence = \" \".join([words[i] for i in solution])\n#     submission = pd.DataFrame({'id': [0], 'text': [sentence] })\n#     perplexities = scorer.get_perplexity(submission[\"text\"].tolist())\n#     # print(f\"{perplexities[0]} || {sentence}\")\n#     return perplexities[0]\n\n# tabuSearch = TabuSearch(words, __calculate_fitness, tabu_tenure=10, stop_on_non_improvement=50, debug=True)\n\n# tabuSearch.optimize(init)","metadata":{"execution":{"iopub.status.busy":"2024-12-21T13:38:29.623844Z","iopub.execute_input":"2024-12-21T13:38:29.624186Z","iopub.status.idle":"2024-12-21T13:38:29.635487Z","shell.execute_reply.started":"2024-12-21T13:38:29.624164Z","shell.execute_reply":"2024-12-21T13:38:29.634614Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom itertools import permutations\n\nclass WhaleOptimization:\n    def __init__(self, sentence: str, scorer,\n                 n_whales: int = 20, max_iter: int = 80,\n                 tabu_tenure=10, stop_on_non_improvement=20, tabu_max_iter=50,\n                 debug=False):\n        self.words = sentence.split(' ')\n        self.n = len(self.words)\n        self.scorer = scorer\n        self.n_whales = n_whales\n        self.max_iter = max_iter\n        self.debug = debug\n        self.cur_whale = None\n        self.TabuSearch = TabuSearch(self.n, self.__calculate_fitness, tabu_tenure=tabu_tenure, stop_on_non_improvement=stop_on_non_improvement,max_iter=tabu_max_iter, debug=debug)\n    \n    def __create_initial_sols(self) -> np.ndarray:\n        \"\"\"Create a random permutation solution\"\"\"\n        return np.random.permutation(self.n)\n    \n    def log(self, msg):\n        if self.debug:\n            if self.cur_whale is None:\n                print(f\"[WOA] {msg}\")\n            else:\n                print(f\"[WOA] [WHALE {self.cur_whale + 1}] {msg}\")\n    \n    def _compute_A(self, a: float):\n        r = np.random.uniform(0.0, 1.0, size=1)\n        return (2.0*np.multiply(a, r)) - a\n\n    def _compute_C(self):\n        return 2.0 * np.random.uniform(0.0, 1.0, size=1)\n    \n    def __to_sentence_text(self, sol):\n        return \" \".join([self.words[i] for i in sol])\n    \n    def __calculate_fitness(self, solution: np.ndarray) -> float:\n        sentence = self.__to_sentence_text(solution)\n        submission = pd.DataFrame({'id': [0], 'text': [sentence] })\n        perplexities = scorer.get_perplexity(submission[\"text\"].tolist()) # TODO use self to access the scorer\n        # print(f\"{perplexities[0]} || {sentence}\")\n        return perplexities[0]\n    \n    def __encircling_prey(self, current_pos: np.ndarray, best_pos: np.ndarray, A: float, C: float) -> np.ndarray:\n        D = abs(C * best_pos - current_pos)\n        new_pos = best_pos - A * D\n        return np.argsort(new_pos)\n    \n    def __search_for_prey(self, current_pos: np.ndarray, random_pos: np.ndarray, A: float, C: float) -> np.ndarray:\n        D = abs(C * random_pos - current_pos)\n        new_pos = random_pos - A * D\n        return np.argsort(new_pos) \n    \n    def __bubble_net_attack(self, current_pos: np.ndarray, best_pos: np.ndarray, l: float) -> np.ndarray:\n        D = abs(best_pos - current_pos)\n        b = 1\n        new_pos = D * np.exp(l * b) * np.cos(2 * np.pi * l) + best_pos\n        return np.argsort(new_pos)\n    \n    def __amend_position(self, position: np.ndarray) -> np.ndarray:\n        \"\"\"Ensure position is a valid permutation.\"\"\"\n        return np.argsort(position)\n   \n    def __local_search(self, solution: np.ndarray) -> Tuple[np.ndarray, float]:\n        return self.TabuSearch.optimize(solution)\n    \n    def optimize(self) -> Tuple[np.ndarray, float, List[float], List[list]]:\n        # Initialize population with local search improvement\n        population = []\n        fitness_values = []\n        for w in range(self.n_whales):\n            self.cur_whale = w\n            solution = self.__create_initial_sols()\n            improved_solution, improved_fitness = self.__local_search(solution)\n            self.log(f\"{improved_solution} | {improved_fitness}\")\n            population.append(improved_solution)\n            fitness_values.append(improved_fitness)\n        self.cur_whale=None\n\n        self.log(\"------------------------------\")\n        self.log(f\"[WHALES]\")\n        self.log(population)\n        self.log(fitness_values)\n        self.log(\"------------------------------\")\n        \n        best_idx = np.argmin(fitness_values)\n        best_pos = population[best_idx].copy()\n        best_fitness = fitness_values[best_idx]\n        \n        t = 0\n        while t < self.max_iter:\n            self.log(f\"[ITER] {t+1}\")\n            for i in range(self.n_whales):\n                self.cur_whale = i\n                self.log(f\"{population[i]} | fitness_values[i]\")\n                a = 2 - t * (2 / self.max_iter)\n                r = random.random()\n                A = self._compute_A(a)  \n                C = self._compute_C() \n                l = random.uniform(-1, 1)\n                p = random.random()\n            \n                if p < 0.5:\n                    if abs(A) < 1:\n                        new_pos = self.__encircling_prey(population[i], best_pos, A, C)\n                    else:\n                        rand_idx = random.randint(0, self.n_whales-1)\n                        random_pos = population[rand_idx]\n                        new_pos = self.__search_for_prey(population[i], random_pos, A, C)\n                else:\n                    new_pos = self.__bubble_net_attack(population[i], best_pos, l)\n                \n                new_pos = self.__amend_position(new_pos)\n                self.log(f\"[NEW POSITION] {new_pos}\")\n                # Apply local search to improve the new position\n                improved_pos, improved_fitness = self.__local_search(new_pos)\n                self.log(f\"[IMPROVE POSITION] {new_pos}, [{improved_fitness}]\")\n                \n                population[i] = improved_pos\n                fitness_values[i] = improved_fitness\n                \n                if improved_fitness < best_fitness:\n                    best_pos = improved_pos.copy()\n                    best_fitness = improved_fitness\n                    self.log(f\"[BEST] {best_pos}, [{best_fitness}]\")\n            self.cur_whale=None\n            t += 1\n        \n        return best_pos, best_fitness","metadata":{"execution":{"iopub.status.busy":"2024-12-21T14:21:56.967748Z","iopub.execute_input":"2024-12-21T14:21:56.968062Z","iopub.status.idle":"2024-12-21T14:21:56.983770Z","shell.execute_reply.started":"2024-12-21T14:21:56.968036Z","shell.execute_reply":"2024-12-21T14:21:56.982983Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# text = submission['text'][0]\n\ntext = 'advent chimney elf family fireplace gingerbread mistletoe ornament reindeer scrooge'\n\nwoa = WhaleOptimization(text, score, n_whales=3, max_iter=50, debug=True, )\nwoa.optimize()","metadata":{"execution":{"iopub.status.busy":"2024-12-21T14:22:01.080275Z","iopub.execute_input":"2024-12-21T14:22:01.080558Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[LOCAL SEARCH] start [0 8 5 3 2 9 6 7 4 1]\n[LOCAL SEARCH] [IM] [4/50] [1645.7186324761606]\n[LOCAL SEARCH] [IM] [6/50] [1609.1409647660719]\n[LOCAL SEARCH] [IM] [7/50] [1583.351496700381]\n[LOCAL SEARCH] [IM] [13/50] [1525.9491008824261]\n[LOCAL SEARCH] [IM] [15/50] [1467.322977449454]\n[LOCAL SEARCH] [IM] [19/50] [1355.1417478558085]\n[LOCAL SEARCH] [IM] [21/50] [1241.8455335674785]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 7 3 4 1] | 1241.8455335674785\n[WOA] [WHALE 1] [0 9 6 8 2 5 7 3 4 1] | 1241.8455335674785\n[LOCAL SEARCH] start [9 7 2 8 6 1 3 4 0 5]\n[LOCAL SEARCH] [IM] [1/50] [1827.705390509874]\n[LOCAL SEARCH] [IM] [2/50] [1768.7237414754452]\n[LOCAL SEARCH] [IM] [8/50] [1479.6509591759966]\n[LOCAL SEARCH] [IM] [14/50] [1349.6616044431855]\n[LOCAL SEARCH] [IM] [16/50] [1243.64462748415]\n[LOCAL SEARCH] [NO IM] break; [9 6 8 2 1 4 7 3 0 5] | 1243.64462748415\n[WOA] [WHALE 2] [9 6 8 2 1 4 7 3 0 5] | 1243.64462748415\n[LOCAL SEARCH] start [0 3 8 7 5 1 4 9 2 6]\n[LOCAL SEARCH] [IM] [1/50] [4843.807997342151]\n[LOCAL SEARCH] [IM] [7/50] [3210.9518559465655]\n[LOCAL SEARCH] [IM] [19/50] [3179.5686080177834]\n[LOCAL SEARCH] [IM] [20/50] [2689.288082054477]\n[LOCAL SEARCH] [IM] [22/50] [2213.770965440546]\n[LOCAL SEARCH] [IM] [23/50] [2010.2277125342425]\n[LOCAL SEARCH] [IM] [32/50] [1925.4368818976902]\n[LOCAL SEARCH] [IM] [39/50] [1829.6141390706312]\n[LOCAL SEARCH] [IM] [40/50] [1799.1618193287522]\n[WOA] [WHALE 3] [0 9 2 5 3 8 7 4 1 6] | 1799.1618193287522\n[WOA] ------------------------------\n[WOA] [WHALES]\n[WOA] [array([0, 9, 6, 8, 2, 5, 7, 3, 4, 1]), array([9, 6, 8, 2, 1, 4, 7, 3, 0, 5]), array([0, 9, 2, 5, 3, 8, 7, 4, 1, 6])]\n[WOA] [1241.8455335674785, 1243.64462748415, 1799.1618193287522]\n[WOA] ------------------------------\n[WOA] [ITER] 1\n[WOA] [WHALE 1] [0 9 6 8 2 5 7 3 4 1] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 7 3 4 1]\n[LOCAL SEARCH] start [0 9 6 8 2 5 7 3 4 1]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 7 3 4 1] | 1241.8455335674785\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 7 3 4 1], [1241.8455335674785]\n[WOA] [WHALE 2] [9 6 8 2 1 4 7 3 0 5] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 8 6 3 4 7 9 5 2 1]\n[LOCAL SEARCH] start [0 8 6 3 4 7 9 5 2 1]\n[LOCAL SEARCH] [IM] [1/50] [2637.3241020146943]\n[LOCAL SEARCH] [IM] [2/50] [2206.4329537905965]\n[LOCAL SEARCH] [IM] [6/50] [1638.2710901212458]\n[LOCAL SEARCH] [IM] [14/50] [1524.669010655018]\n[LOCAL SEARCH] [IM] [15/50] [1431.4077630116424]\n[LOCAL SEARCH] [IM] [18/50] [1327.4938831305146]\n[LOCAL SEARCH] [NO IM] break; [0 2 6 9 8 5 7 3 4 1] | 1327.4938831305146\n[WOA] [WHALE 2] [IMPROVE POSITION] [0 8 6 3 4 7 9 5 2 1], [1327.4938831305146]\n[WOA] [WHALE 3] [0 9 2 5 3 8 7 4 1 6] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [0 8 7 9 1 5 6 2 4 3]\n[LOCAL SEARCH] start [0 8 7 9 1 5 6 2 4 3]\n[LOCAL SEARCH] [IM] [1/50] [2276.247965353904]\n[LOCAL SEARCH] [IM] [2/50] [1827.9407154761266]\n[LOCAL SEARCH] [IM] [4/50] [1485.4428576037733]\n[LOCAL SEARCH] [IM] [10/50] [1475.045942942023]\n[LOCAL SEARCH] [IM] [16/50] [1386.8454510260187]\n[LOCAL SEARCH] [IM] [28/50] [1189.5504911495311]\n[LOCAL SEARCH] [IM] [30/50] [1138.6130580868632]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 3] [IMPROVE POSITION] [0 8 7 9 1 5 6 2 4 3], [1138.6130580868632]\n[WOA] [WHALE 3] [BEST] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [ITER] 2\n[WOA] [WHALE 1] [0 9 6 8 2 5 7 3 4 1] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 7 1 5 2 4 8 3]\n[LOCAL SEARCH] start [0 9 6 7 1 5 2 4 8 3]\n[LOCAL SEARCH] [IM] [1/50] [1945.898640990758]\n[LOCAL SEARCH] [IM] [4/50] [1880.729255854879]\n[LOCAL SEARCH] [IM] [6/50] [1367.2070177716773]\n[LOCAL SEARCH] [IM] [8/50] [1272.8260234439922]\n[LOCAL SEARCH] [IM] [11/50] [1241.8105967313124]\n[LOCAL SEARCH] [IM] [15/50] [1189.5504911495311]\n[LOCAL SEARCH] [IM] [25/50] [1138.6130580868632]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 7 1 5 2 4 8 3], [1138.6130580868632]\n[WOA] [WHALE 2] [0 2 6 9 8 5 7 3 4 1] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 9 2 5 8 1 7 3 6 4]\n[LOCAL SEARCH] start [0 9 2 5 8 1 7 3 6 4]\n[LOCAL SEARCH] [IM] [1/50] [2121.3342427287903]\n[LOCAL SEARCH] [IM] [2/50] [1806.1656443305535]\n[LOCAL SEARCH] [IM] [3/50] [1514.4119889228393]\n[LOCAL SEARCH] [IM] [4/50] [1458.1753844346506]\n[LOCAL SEARCH] [NO IM] break; [0 9 2 5 3 8 6 7 1 4] | 1458.1753844346506\n[WOA] [WHALE 2] [IMPROVE POSITION] [0 9 2 5 8 1 7 3 6 4], [1458.1753844346506]\n[WOA] [WHALE 3] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [0 8 1 3 4 9 7 6 2 5]\n[LOCAL SEARCH] start [0 8 1 3 4 9 7 6 2 5]\n[LOCAL SEARCH] [IM] [1/50] [4520.578210753467]\n[LOCAL SEARCH] [IM] [4/50] [3596.8740743805406]\n[LOCAL SEARCH] [IM] [6/50] [3246.9214173413134]\n[LOCAL SEARCH] [IM] [7/50] [2695.048157502164]\n[LOCAL SEARCH] [IM] [8/50] [2625.278980494886]\n[LOCAL SEARCH] [IM] [9/50] [2307.7869266580647]\n[LOCAL SEARCH] [IM] [11/50] [2168.235014902592]\n[LOCAL SEARCH] [IM] [18/50] [2059.8221198074807]\n[LOCAL SEARCH] [IM] [20/50] [1893.3454382244915]\n[LOCAL SEARCH] [IM] [25/50] [1759.095719969959]\n[LOCAL SEARCH] [NO IM] break; [0 6 9 3 8 1 2 4 7 5] | 1759.095719969959\n[WOA] [WHALE 3] [IMPROVE POSITION] [0 8 1 3 4 9 7 6 2 5], [1759.095719969959]\n[WOA] [ITER] 3\n[WOA] [WHALE 1] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [WHALE 2] [0 9 2 5 3 8 6 7 1 4] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 6 7 8 1 5 3 4 9 2]\n[LOCAL SEARCH] start [0 6 7 8 1 5 3 4 9 2]\n[LOCAL SEARCH] [IM] [1/50] [2172.919476878551]\n[LOCAL SEARCH] [IM] [2/50] [1999.372776334683]\n[LOCAL SEARCH] [IM] [3/50] [1595.4198904946415]\n[LOCAL SEARCH] [NO IM] break; [0 6 3 5 9 1 8 7 4 2] | 1595.4198904946415\n[WOA] [WHALE 2] [IMPROVE POSITION] [0 6 7 8 1 5 3 4 9 2], [1595.4198904946415]\n[WOA] [WHALE 3] [0 6 9 3 8 1 2 4 7 5] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [1 8 5 7 0 4 2 6 9 3]\n[LOCAL SEARCH] start [1 8 5 7 0 4 2 6 9 3]\n[LOCAL SEARCH] [IM] [1/50] [2162.8025101367066]\n[LOCAL SEARCH] [IM] [4/50] [2034.7782583638455]\n[LOCAL SEARCH] [IM] [9/50] [1995.6123915879182]\n[LOCAL SEARCH] [IM] [10/50] [1915.047109117047]\n[LOCAL SEARCH] [IM] [11/50] [1784.6482634983429]\n[LOCAL SEARCH] [IM] [13/50] [1651.0910791162178]\n[LOCAL SEARCH] [IM] [19/50] [1490.5728081156867]\n[LOCAL SEARCH] [IM] [20/50] [1284.7420968990798]\n[LOCAL SEARCH] [IM] [31/50] [1232.8925554487057]\n[WOA] [WHALE 3] [IMPROVE POSITION] [1 8 5 7 0 4 2 6 9 3], [1232.8925554487057]\n[WOA] [ITER] 4\n[WOA] [WHALE 1] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [WHALE 2] [0 6 3 5 9 1 8 7 4 2] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 9 6 8 3 1 2 5 7 4]\n[LOCAL SEARCH] start [0 9 6 8 3 1 2 5 7 4]\n[LOCAL SEARCH] [IM] [1/50] [1573.6156167652714]\n[LOCAL SEARCH] [IM] [4/50] [1477.9029277429051]\n[LOCAL SEARCH] [IM] [7/50] [1437.3253702868476]\n[LOCAL SEARCH] [IM] [13/50] [1319.436312590403]\n[LOCAL SEARCH] [IM] [30/50] [1267.424302798481]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 7 3 1 4] | 1267.424302798481\n[WOA] [WHALE 2] [IMPROVE POSITION] [0 9 6 8 3 1 2 5 7 4], [1267.424302798481]\n[WOA] [WHALE 3] [1 9 6 8 5 2 4 0 7 3] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [1 9 6 8 5 2 4 0 7 3]\n[LOCAL SEARCH] start [1 9 6 8 5 2 4 0 7 3]\n[LOCAL SEARCH] [NO IM] break; [1 9 6 8 5 2 4 0 7 3] | 1232.8925554487057\n[WOA] [WHALE 3] [IMPROVE POSITION] [1 9 6 8 5 2 4 0 7 3], [1232.8925554487057]\n[WOA] [ITER] 5\n[WOA] [WHALE 1] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [WHALE 2] [0 9 6 8 2 5 7 3 1 4] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [2 9 7 8 3 6 0 4 1 5]\n[LOCAL SEARCH] start [2 9 7 8 3 6 0 4 1 5]\n[LOCAL SEARCH] [IM] [1/50] [3288.5710806689995]\n[LOCAL SEARCH] [IM] [4/50] [3190.4548680084604]\n[LOCAL SEARCH] [IM] [5/50] [2878.8043455473626]\n[LOCAL SEARCH] [IM] [6/50] [2636.267951276565]\n[LOCAL SEARCH] [IM] [13/50] [2099.338021246382]\n[LOCAL SEARCH] [IM] [15/50] [1963.6074667061491]\n[LOCAL SEARCH] [NO IM] break; [2 6 9 3 8 1 4 0 7 5] | 1963.6074667061491\n[WOA] [WHALE 2] [IMPROVE POSITION] [2 9 7 8 3 6 0 4 1 5], [1963.6074667061491]\n[WOA] [WHALE 3] [1 9 6 8 5 2 4 0 7 3] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [0 9 6 8 2 5 1 3 7 4]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 3 7 4]\n[LOCAL SEARCH] [IM] [1/50] [1267.424302798481]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 7 3 1 4] | 1267.424302798481\n[WOA] [WHALE 3] [IMPROVE POSITION] [0 9 6 8 2 5 1 3 7 4], [1267.424302798481]\n[WOA] [ITER] 6\n[WOA] [WHALE 1] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [WHALE 2] [2 6 9 3 8 1 4 0 7 5] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 8 7 9 3 6 1 5 4 2]\n[LOCAL SEARCH] start [0 8 7 9 3 6 1 5 4 2]\n[LOCAL SEARCH] [IM] [1/50] [3270.9801631962687]\n[LOCAL SEARCH] [IM] [6/50] [3095.800338723675]\n[LOCAL SEARCH] [IM] [7/50] [2428.5743597512796]\n[LOCAL SEARCH] [IM] [12/50] [1970.574790786004]\n[LOCAL SEARCH] [IM] [21/50] [1792.4979570270414]\n[LOCAL SEARCH] [IM] [25/50] [1636.2084895311962]\n[LOCAL SEARCH] [IM] [26/50] [1584.6702770504612]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 3 8 5 7 4 1 2] | 1584.6702770504612\n[WOA] [WHALE 2] [IMPROVE POSITION] [0 8 7 9 3 6 1 5 4 2], [1584.6702770504612]\n[WOA] [WHALE 3] [0 9 6 8 2 5 7 3 1 4] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [0 9 6 8 1 5 4 3 7 2]\n[LOCAL SEARCH] start [0 9 6 8 1 5 4 3 7 2]\n[LOCAL SEARCH] [IM] [1/50] [1952.2286833216854]\n[LOCAL SEARCH] [IM] [2/50] [1584.4096062556703]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 5 1 7 3 4 2] | 1584.4096062556703\n[WOA] [WHALE 3] [IMPROVE POSITION] [0 9 6 8 1 5 4 3 7 2], [1584.4096062556703]\n[WOA] [ITER] 7\n[WOA] [WHALE 1] [0 9 6 8 2 5 1 4 7 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [2 9 5 8 7 0 6 4 1 3]\n[LOCAL SEARCH] start [2 9 5 8 7 0 6 4 1 3]\n[LOCAL SEARCH] [IM] [1/50] [4092.821639906849]\n[LOCAL SEARCH] [IM] [5/50] [2483.8556972719516]\n[LOCAL SEARCH] [IM] [6/50] [2410.1634282344694]\n[LOCAL SEARCH] [IM] [7/50] [1802.0836475115966]\n[LOCAL SEARCH] [IM] [13/50] [1637.6556291950828]\n[LOCAL SEARCH] [NO IM] break; [2 6 8 5 9 7 0 1 4 3] | 1637.6556291950828\n[WOA] [WHALE 1] [IMPROVE POSITION] [2 9 5 8 7 0 6 4 1 3], [1637.6556291950828]\n[WOA] [WHALE 2] [0 9 6 3 8 5 7 4 1 2] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [2 9 8 7 1 6 0 5 4 3]\n[LOCAL SEARCH] start [2 9 8 7 1 6 0 5 4 3]\n[LOCAL SEARCH] [IM] [1/50] [4717.988943839116]\n[LOCAL SEARCH] [IM] [2/50] [3313.3523541260843]\n[LOCAL SEARCH] [IM] [5/50] [2450.3907039896862]\n[LOCAL SEARCH] [IM] [11/50] [2049.9931997120752]\n[LOCAL SEARCH] [NO IM] break; [2 6 9 8 0 5 7 1 4 3] | 2049.9931997120752\n[WOA] [WHALE 2] [IMPROVE POSITION] [2 9 8 7 1 6 0 5 4 3], [2049.9931997120752]\n[WOA] [WHALE 3] [0 9 6 8 5 1 7 3 4 2] | fitness_values[i]\n[WOA] [WHALE 3] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 3] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [ITER] 8\n[WOA] [WHALE 1] [2 6 8 5 9 7 0 1 4 3] | fitness_values[i]\n[WOA] [WHALE 1] [NEW POSITION] [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] start [0 9 6 8 2 5 1 4 7 3]\n[LOCAL SEARCH] [NO IM] break; [0 9 6 8 2 5 1 4 7 3] | 1138.6130580868632\n[WOA] [WHALE 1] [IMPROVE POSITION] [0 9 6 8 2 5 1 4 7 3], [1138.6130580868632]\n[WOA] [WHALE 2] [2 6 9 8 0 5 7 1 4 3] | fitness_values[i]\n[WOA] [WHALE 2] [NEW POSITION] [0 9 4 7 2 5 3 6 8 1]\n[LOCAL SEARCH] start [0 9 4 7 2 5 3 6 8 1]\n[LOCAL SEARCH] [IM] [1/50] [2237.5091805095503]\n[LOCAL SEARCH] [IM] [3/50] [2095.45157245847]\n[LOCAL SEARCH] [IM] [4/50] [1486.071265317601]\n[LOCAL SEARCH] [IM] [6/50] [1395.4610595889603]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}